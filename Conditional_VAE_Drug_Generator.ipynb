{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/DD/blob/main/Conditional_VAE_Drug_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D9EyueZqCNYB",
        "outputId": "7a372d96-4e7d-4f71-86ae-c2834826d400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.3.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.3.5-cp312-cp312-manylinux_2_28_x86_64.whl (36.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.3.5\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgGdjLecJ31t",
        "outputId": "c5865c61-e208-47fe-dff6-51d2843f3bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NEW CODE WITH PROTEIN UPDATING: To make the model more effective, we need to create a richer, more meaningful representation of the protein sequence. We can do this with the data you already have by using a technique called transfer learning. This involves using a pre-trained protein language model (PLM).\n",
        "\n",
        "#These models, like ESM or ProtT5, have been trained on millions of protein sequences and have learned a deep understanding of protein biology. Instead of a simple one-hot vector, they can transform a protein sequence into a dense numerical vector (an embedding) that captures a wealth of information about its function, structure, and evolutionary relationships.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppress RDKit warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Global constants for a comprehensive SMILES vocabulary ---\n",
        "def create_comprehensive_smiles_vocab():\n",
        "    \"\"\"\n",
        "    Creates a comprehensive SMILES token vocabulary based on the periodic table,\n",
        "    numbers, and common SMILES characters.\n",
        "    \"\"\"\n",
        "    periodic_table_elements = [\n",
        "        'H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si',\n",
        "        'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
        "        'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb',\n",
        "        'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
        "        'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho',\n",
        "        'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
        "        'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np',\n",
        "        'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg',\n",
        "        'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og'\n",
        "    ]\n",
        "    # Common SMILES single characters\n",
        "    single_char_tokens = [\n",
        "        '(', ')', '[', ']', '+', '-', '=', '#', '.', ':', '/', '\\\\',\n",
        "        'c', 'n', 'o', 's', '`', '@'\n",
        "    ]\n",
        "    # Numbers\n",
        "    numbers = [str(i) for i in range(10)]\n",
        "\n",
        "    # Combine all tokens and remove duplicates\n",
        "    all_tokens = set(periodic_table_elements + single_char_tokens + numbers)\n",
        "    # Add start and padding tokens\n",
        "    all_tokens.add('#') # Start token\n",
        "    all_tokens.add('`') # Padding token\n",
        "\n",
        "    # Sort tokens by length in descending order to handle multi-character tokens correctly\n",
        "    sorted_tokens = sorted(list(all_tokens), key=len, reverse=True)\n",
        "    # Create the dictionary\n",
        "    smiles_token_dict = {token: i for i, token in enumerate(sorted_tokens)}\n",
        "\n",
        "    return smiles_token_dict, sorted_tokens\n",
        "\n",
        "SMILES_TOKEN_DICT, sorted_tokens = create_comprehensive_smiles_vocab()\n",
        "SMILES_MAX_LEN = 500\n",
        "MAX_PROTEIN_SEQUENCE_LEN = 1000  # New constant to control max protein sequence length\n",
        "HIDDEN_DIM = 64\n",
        "LATENT_DIM = 128\n",
        "NUM_LAYERS = 2\n",
        "MAX_EPOCHS = 1\n",
        "BATCH_SIZE = 1000\n",
        "PATIENCE = 15\n",
        "LEARNING_RATE = 1e-3\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/Drug_Database/BindingDB_CVAE_best_model.pt'\n",
        "\n",
        "# --- Data Preprocessing and PyTorch Dataset ---\n",
        "def get_smiles_tokens(smiles_string, special_tokens):\n",
        "    \"\"\"\n",
        "    Tokenizes a SMILES string using a predefined list of special tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles_string):\n",
        "        matched = False\n",
        "        for token in special_tokens:\n",
        "            if smiles_string.startswith(token, i):\n",
        "                tokens.append(token)\n",
        "                i += len(token)\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            tokens.append(smiles_string[i])\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "def smiles_to_one_hot(smiles, token_to_idx, max_len, sorted_tokens):\n",
        "    \"\"\"Encodes a SMILES string into a one-hot vector with padding.\"\"\"\n",
        "    tokens = get_smiles_tokens(smiles, sorted_tokens)\n",
        "\n",
        "    if len(tokens) > max_len:\n",
        "        tokens = tokens[:max_len]\n",
        "\n",
        "    # Pad with padding token\n",
        "    padded_tokens = tokens + ['`'] * (max_len - len(tokens))\n",
        "\n",
        "    one_hot_vector = np.zeros((max_len, len(token_to_idx)), dtype=np.float32)\n",
        "    for i, token in enumerate(padded_tokens):\n",
        "        if token in token_to_idx:\n",
        "            one_hot_vector[i, token_to_idx[token]] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "def get_protein_embedding(seq):\n",
        "    \"\"\"\n",
        "    A simple, placeholder protein embedding function.\n",
        "    In a real-world scenario, you would use a more sophisticated method,\n",
        "    like a pre-trained protein language model (e.g., from the ProtTrans or ESM family)\n",
        "    for better performance on complex protein sequences.\n",
        "    \"\"\"\n",
        "    protein_vocab = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10,\n",
        "                     'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
        "    embedding = np.zeros(len(protein_vocab), dtype=np.float32)\n",
        "    for amino_acid in seq:\n",
        "        if amino_acid in protein_vocab:\n",
        "            embedding[protein_vocab[amino_acid]] = 1\n",
        "    return embedding\n",
        "\n",
        "def get_advanced_protein_embedding(seq):\n",
        "    \"\"\"\n",
        "    A placeholder function for a more advanced protein embedding.\n",
        "\n",
        "    In a real-world application, this function would use a pre-trained\n",
        "    protein language model (PLM) like ESM-2 or ProtT5.\n",
        "\n",
        "    Example using a conceptual library call:\n",
        "\n",
        "    from transformers import T5EncoderModel, T5Tokenizer\n",
        "\n",
        "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_uniref50')\n",
        "    model = T5EncoderModel.from_pretrained('Rostlab/prot_t5_xl_uniref50')\n",
        "\n",
        "    # Tokenize and get embedding\n",
        "    encoded_input = tokenizer(seq, return_tensors='pt', max_length=1000, padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        embedding = model(**encoded_input).last_hidden_state.mean(dim=1).squeeze()\n",
        "\n",
        "    return embedding.numpy()\n",
        "\n",
        "    The dimension of the embedding would be around 1024, significantly larger\n",
        "    and more informative than the simple one-hot encoding.\n",
        "\n",
        "    For now, we'll return a placeholder vector to avoid a runtime error.\n",
        "    \"\"\"\n",
        "    # Placeholder for the advanced embedding dimension\n",
        "    ADVANCED_PROTEIN_EMBEDDING_DIM = 1024\n",
        "    return np.random.rand(ADVANCED_PROTEIN_EMBEDDING_DIM).astype(np.float32)\n",
        "\n",
        "class SmilesProteinDataset(Dataset):\n",
        "    \"\"\"Dataset for loading SMILES and Protein sequence pairs.\"\"\"\n",
        "    def __init__(self, smiles_list, protein_list, smiles_token_dict, smiles_max_len, sorted_tokens, embedding_function):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.protein_list = protein_list\n",
        "        self.smiles_token_dict = smiles_token_dict\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.sorted_tokens = sorted_tokens\n",
        "        self.embedding_function = embedding_function\n",
        "        # The protein embedding dimension is determined from the first sequence in the list\n",
        "        self.protein_embedding_dim = len(self.embedding_function(self.protein_list[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles_list[idx]\n",
        "        protein = self.protein_list[idx]\n",
        "        smiles_one_hot = smiles_to_one_hot(smiles, self.smiles_token_dict, self.smiles_max_len, self.sorted_tokens)\n",
        "        protein_embedding = self.embedding_function(protein)\n",
        "        return torch.tensor(smiles_one_hot, dtype=torch.float32), torch.tensor(protein_embedding, dtype=torch.float32)\n",
        "\n",
        "# --- Conditional VAE Model Definition ---\n",
        "\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, smiles_vocab_size, protein_embedding_dim, hidden_dim, latent_dim, smiles_max_len, num_layers):\n",
        "        super(ConditionalVAE, self).__init__()\n",
        "\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.smiles_vocab_size = smiles_vocab_size\n",
        "        self.protein_embedding_dim = protein_embedding_dim\n",
        "\n",
        "        # Encoder: takes smiles and protein embedding as input\n",
        "        self.encoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        # NOTE: This MLP now needs to take the more complex protein embedding as input\n",
        "        self.encoder_protein_mlp = nn.Sequential(\n",
        "            nn.Linear(protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder: takes latent vector and protein embedding as input\n",
        "        self.decoder_gru_input_mlp = nn.Sequential(\n",
        "            nn.Linear(latent_dim + protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc_output = nn.Linear(hidden_dim, smiles_vocab_size)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick to sample from N(mu, var)\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encoder(self, smiles_one_hot, protein_embedding):\n",
        "        _, hidden_smiles = self.encoder_rnn(smiles_one_hot)\n",
        "        # Ensure protein embedding has the correct shape for broadcasting\n",
        "        hidden_protein = self.encoder_protein_mlp(protein_embedding).unsqueeze(0).repeat(hidden_smiles.size(0), 1, 1)\n",
        "        combined_hidden = hidden_smiles + hidden_protein\n",
        "        final_hidden_state = combined_hidden[-1, :, :]\n",
        "        mu = self.fc_mu(final_hidden_state)\n",
        "        logvar = self.fc_logvar(final_hidden_state)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decoder(self, z, protein_embedding):\n",
        "        z_with_protein = torch.cat((z, protein_embedding), dim=1)\n",
        "        initial_hidden = self.decoder_gru_input_mlp(z_with_protein).unsqueeze(0)\n",
        "        initial_hidden = initial_hidden.repeat(self.decoder_rnn.num_layers, 1, 1)\n",
        "        decoder_input = torch.zeros(z.size(0), self.smiles_max_len, self.smiles_vocab_size).to(z.device)\n",
        "        output, _ = self.decoder_rnn(decoder_input, initial_hidden)\n",
        "        output = self.fc_output(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, smiles_one_hot, protein_embedding):\n",
        "        mu, logvar = self.encoder(smiles_one_hot, protein_embedding)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_smiles = self.decoder(z, protein_embedding)\n",
        "        return reconstructed_smiles, mu, logvar\n",
        "\n",
        "# --- Training Loop and Generation ---\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar, smiles_vocab_size):\n",
        "    \"\"\"VAE loss function: BCE + KL divergence.\"\"\"\n",
        "    # Ensure dimensions are compatible for BCE calculation\n",
        "    recon_x_flat = recon_x.view(-1, smiles_vocab_size)\n",
        "    x_flat = x.view(-1, smiles_vocab_size)\n",
        "    BCE = nn.functional.binary_cross_entropy_with_logits(recon_x_flat, x_flat, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def train_model(model, dataloader, optimizer, device, smiles_vocab_size):\n",
        "    \"\"\"Trains the VAE model for one epoch with a progress bar.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    tqdm_loader = tqdm(dataloader, desc=\"Training\")\n",
        "    for smiles_oh, protein_emb in tqdm_loader:\n",
        "        smiles_oh = smiles_oh.to(device)\n",
        "        protein_emb = protein_emb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "        loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Update the progress bar with the current batch loss\n",
        "        tqdm_loader.set_postfix(batch_loss=loss.item() / smiles_oh.size(0))\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def validate_model(model, dataloader, device, smiles_vocab_size):\n",
        "    \"\"\"Evaluates the model on the validation set.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        tqdm_loader = tqdm(dataloader, desc=\"Validation\")\n",
        "        for smiles_oh, protein_emb in tqdm_loader:\n",
        "            smiles_oh = smiles_oh.to(device)\n",
        "            protein_emb = protein_emb.to(device)\n",
        "\n",
        "            reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "            loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "            total_loss += loss.item()\n",
        "            # Update the progress bar with the current batch loss\n",
        "            tqdm_loader.set_postfix(batch_loss=loss.item() / smiles_oh.size(0))\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def generate_new_molecules(model, smiles_token_dict, protein_seq, num_molecules, device, latent_dim):\n",
        "    \"\"\"Generates and visualizes new molecules for a given protein sequence.\"\"\"\n",
        "    model.eval()\n",
        "    idx_to_token = {v: k for k, v in smiles_token_dict.items()}\n",
        "    generated_molecules = []\n",
        "\n",
        "    # Prepare the protein embedding for a single sequence\n",
        "    # NOTE: We now use the advanced embedding function here too\n",
        "    protein_embedding = get_advanced_protein_embedding(protein_seq)\n",
        "    protein_embedding = torch.tensor(protein_embedding, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    print(f\"\\nAttempting to generate {num_molecules} molecules for protein sequence: {protein_seq}\")\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_molecules):\n",
        "            # Sample a vector from the latent space\n",
        "            z = torch.randn(1, latent_dim).to(device)\n",
        "            # Use the decoder to generate a one-hot encoded SMILES string\n",
        "            generated_output = model.decoder(z, protein_embedding)\n",
        "\n",
        "            # Use softmax to get probabilities for each token and then select the most likely one\n",
        "            probabilities = nn.functional.softmax(generated_output, dim=-1)\n",
        "            predicted_indices = torch.argmax(probabilities, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "            generated_smiles = \"\"\n",
        "            for token_idx in predicted_indices:\n",
        "                token = idx_to_token.get(token_idx, '')\n",
        "                # Stop decoding when a padding token is encountered\n",
        "                if token == '`':\n",
        "                    break\n",
        "                generated_smiles += token\n",
        "\n",
        "            # Validate and display the generated SMILES string as an image\n",
        "            mol = Chem.MolFromSmiles(generated_smiles)\n",
        "            if mol is not None:\n",
        "                print(f\"Generated molecule (valid SMILES): {generated_smiles}\")\n",
        "                # You can't display images directly in this environment, but the code is ready for it.\n",
        "            else:\n",
        "                print(f\"Generated molecule (invalid SMILES): {generated_smiles}\")\n",
        "\n",
        "            generated_molecules.append(generated_smiles)\n",
        "\n",
        "    return generated_molecules\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Determine the device to use (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Define the path to the newly created CSV file in Google Drive\n",
        "    csv_file_path = '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'\n",
        "\n",
        "    # Define an example protein sequence to predict for\n",
        "    target_protein_sequence = 'MGNASNDSQSEDCETRQWLPPGESPAISSVMFSAGVLGNLIALALLARRWRGDVGCSAGRRSSLSLFHVLVTELVFTDLLGTCLISPVVLASYARNQTLVALAPESRACTYFAFAMTFFSLATMLMLFAMALERYLSIGHPYFYQRRVSRSGGLAVLPVIYAVSLLFCSLPLLDYGQYVQYCPGTWCFIRHGRTAYLQLYATLLLLLIVSVLACNFSVILNLIRMHRRSRRSRCGPSLGSGRGGPGARRRGERVSMAEETDHLILLAIMTITFAVCSLPFTIFAYMNETSSRKEKWDLQALRFLSINSIIDPWVFAILRPPVLRLMRSVLCCRISLRTQDATQTSCSTQSDASKQADL'\n",
        "\n",
        "    # --- Data Loading ---\n",
        "    try:\n",
        "        # Load the CSV file from the specified Google Drive path\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "        # Ensure the column names match the new dataset\n",
        "        smiles_list = df['SMILES'].tolist()\n",
        "        protein_list = df['Protein_Sequence'].tolist()\n",
        "        print(f\"Successfully loaded {len(smiles_list)} data points from '{csv_file_path}'.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The data file '{csv_file_path}' was not found.\")\n",
        "        print(\"Please ensure the file has been created by the previous script and is in the correct directory.\")\n",
        "        exit()\n",
        "\n",
        "    # --- Data Filtering ---\n",
        "    initial_count = len(smiles_list)\n",
        "    filtered_smiles = []\n",
        "    filtered_proteins = []\n",
        "    for smiles, protein in zip(smiles_list, protein_list):\n",
        "        # Filter out rows with missing or invalid protein sequences\n",
        "        if pd.isna(protein) or not isinstance(protein, str) or not protein.strip():\n",
        "            continue\n",
        "        # Then, apply the length filter\n",
        "        if len(protein) <= MAX_PROTEIN_SEQUENCE_LEN:\n",
        "            filtered_smiles.append(smiles)\n",
        "            filtered_proteins.append(protein)\n",
        "\n",
        "    smiles_list = filtered_smiles\n",
        "    protein_list = filtered_proteins\n",
        "    print(f\"Filtered dataset: Retained {len(smiles_list)} rows out of {initial_count} \"\n",
        "          f\"by removing invalid protein sequences and sequences of length > {MAX_PROTEIN_SEQUENCE_LEN}.\")\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    # NOTE: We now pass the advanced embedding function to the dataset\n",
        "    full_dataset = SmilesProteinDataset(smiles_list, protein_list, SMILES_TOKEN_DICT, SMILES_MAX_LEN, sorted_tokens, get_advanced_protein_embedding)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialize the model and optimizer\n",
        "    # NOTE: The protein embedding dimension is now dynamic based on the advanced embedding model\n",
        "    protein_embedding_dim = full_dataset.protein_embedding_dim\n",
        "    model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        print(f\"--- Epoch {epoch+1}/{MAX_EPOCHS} ---\")\n",
        "        train_loss = train_model(model, train_dataloader, optimizer, device, len(SMILES_TOKEN_DICT))\n",
        "        val_loss = validate_model(model, val_dataloader, device, len(SMILES_TOKEN_DICT))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{MAX_EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Check for improvement and save the best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            print(f\"Validation loss improved. Saving model to {MODEL_SAVE_PATH}\")\n",
        "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Validation loss did not improve. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nTraining complete. Model saved to '{MODEL_SAVE_PATH}'.\")\n",
        "\n",
        "    # --- Generation Process ---\n",
        "    # We load the best model to ensure we are using the one with the best performance\n",
        "    best_model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "    # Generate new molecules using the loaded model\n",
        "    generate_new_molecules(best_model, SMILES_TOKEN_DICT, target_protein_sequence, num_molecules=5, device=device, latent_dim=LATENT_DIM)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtiRScrQSfZ0",
        "outputId": "b30d46c7-1712-45f1-8490-fa35205dc5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Successfully loaded 3046040 data points from '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'.\n",
            "Filtered dataset: Retained 2479480 rows out of 3046040 by removing invalid protein sequences and sequences of length > 1000.\n",
            "Starting training...\n",
            "--- Epoch 1/1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1736/1736 [39:52<00:00,  1.38s/it, batch_loss=218]\n",
            "Validation: 100%|██████████| 744/744 [16:23<00:00,  1.32s/it, batch_loss=224]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Train Loss: 876.2733, Validation Loss: 224.8349\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "\n",
            "Training complete. Model saved to 'best_model.pt'.\n",
            "\n",
            "Attempting to generate 5 molecules for protein sequence: MGNASNDSQSEDCETRQWLPPGESPAISSVMFSAGVLGNLIALALLARRWRGDVGCSAGRRSSLSLFHVLVTELVFTDLLGTCLISPVVLASYARNQTLVALAPESRACTYFAFAMTFFSLATMLMLFAMALERYLSIGHPYFYQRRVSRSGGLAVLPVIYAVSLLFCSLPLLDYGQYVQYCPGTWCFIRHGRTAYLQLYATLLLLLIVSVLACNFSVILNLIRMHRRSRRSRCGPSLGSGRGGPGARRRGERVSMAEETDHLILLAIMTITFAVCSLPFTIFAYMNETSSRKEKWDLQALRFLSINSIIDPWVFAILRPPVLRLMRSVLCCRISLRTQDATQTSCSTQSDASKQADL\n",
            "Generated molecule (invalid SMILES): CCCccccccccccccccccccccccccccccccccccccccccccccccc\n",
            "Generated molecule (invalid SMILES): CCCCCccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
            "Generated molecule (invalid SMILES): CCccccccccccccccccccccccccccccccccc\n",
            "Generated molecule (invalid SMILES): CCCcccccccccccccccccccccccccccccccccccccccccc\n",
            "Generated molecule (invalid SMILES): CCCCcccccccccccccccccccccccccccccccccccccccccccccccccccccc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[06:12:26] non-ring atom 3 marked aromatic\n",
            "[06:12:26] non-ring atom 5 marked aromatic\n",
            "[06:12:26] non-ring atom 2 marked aromatic\n",
            "[06:12:26] non-ring atom 3 marked aromatic\n",
            "[06:12:26] non-ring atom 4 marked aromatic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW CODE FOR COLAB WITH REAL PROTEIN UPDATING\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, EsmModel\n",
        "import gc\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access the dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install missing dependencies if needed\n",
        "!pip install einops\n",
        "\n",
        "# Suppress RDKit warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Global constants for a comprehensive SMILES vocabulary ---\n",
        "def create_comprehensive_smiles_vocab():\n",
        "    \"\"\"\n",
        "    Creates a comprehensive SMILES token vocabulary.\n",
        "    \"\"\"\n",
        "    periodic_table_elements = [\n",
        "        'H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si',\n",
        "        'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
        "        'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb',\n",
        "        'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
        "        'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho',\n",
        "        'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
        "        'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np',\n",
        "        'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg',\n",
        "        'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og'\n",
        "    ]\n",
        "    single_char_tokens = [\n",
        "        '(', ')', '[', ']', '+', '-', '=', '#', '.', ':', '/', '\\\\',\n",
        "        'c', 'n', 'o', 's', '`', '@'\n",
        "    ]\n",
        "    numbers = [str(i) for i in range(10)]\n",
        "    all_tokens = set(periodic_table_elements + single_char_tokens + numbers)\n",
        "    all_tokens.add('#') # Start token\n",
        "    all_tokens.add('`') # Padding token\n",
        "    sorted_tokens = sorted(list(all_tokens), key=len, reverse=True)\n",
        "    smiles_token_dict = {token: i for i, token in enumerate(sorted_tokens)}\n",
        "    return smiles_token_dict, sorted_tokens\n",
        "\n",
        "SMILES_TOKEN_DICT, sorted_tokens = create_comprehensive_smiles_vocab()\n",
        "SMILES_MAX_LEN = 500\n",
        "MAX_PROTEIN_SEQUENCE_LEN = 1000\n",
        "HIDDEN_DIM = 128\n",
        "LATENT_DIM = 64\n",
        "NUM_LAYERS = 2\n",
        "MAX_EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 25\n",
        "LEARNING_RATE = 1e-4\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/Drug_Database/BindingDB_CVAE_best_model_esm.pt'\n",
        "CSV_FILE_PATH = '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'\n",
        "\n",
        "# --- ESM Model Loading and Embedding Function ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the pre-trained ESM-2 model and tokenizer\n",
        "# ***STRATEGY CHANGE: LOAD ESM MODEL TO CPU TO SAVE GPU VRAM***\n",
        "ESM_MODEL_NAME = 'esm2_t12_35M_UR50D'\n",
        "print(f\"Loading ESM-2 model: {ESM_MODEL_NAME} to CPU...\")\n",
        "esm_tokenizer = AutoTokenizer.from_pretrained(f\"facebook/{ESM_MODEL_NAME}\")\n",
        "esm_model = EsmModel.from_pretrained(f\"facebook/{ESM_MODEL_NAME}\")\n",
        "esm_model.eval()\n",
        "ESM_EMBEDDING_DIM = esm_model.config.hidden_size\n",
        "print(f\"ESM model loaded successfully to CPU with embedding dimension: {ESM_EMBEDDING_DIM}\")\n",
        "\n",
        "def get_esm_embedding(seq):\n",
        "    \"\"\"\n",
        "    Generates a protein embedding using a pre-trained ESM-2 model.\n",
        "    \"\"\"\n",
        "    # Keep the model on CPU for most of the time\n",
        "    with torch.no_grad():\n",
        "        seq_spaced = \" \".join(seq)\n",
        "        encoded_input = esm_tokenizer(seq_spaced, return_tensors='pt',\n",
        "                                      max_length=MAX_PROTEIN_SEQUENCE_LEN,\n",
        "                                      padding=True, truncation=True)\n",
        "        # Move input to GPU only for the forward pass\n",
        "        encoded_input = {key: val.to(device) for key, val in encoded_input.items()}\n",
        "        # Move model to GPU for a single forward pass\n",
        "        esm_model_gpu = esm_model.to(device)\n",
        "        output = esm_model_gpu(**encoded_input)\n",
        "        # Move model back to CPU and clear GPU cache\n",
        "        esm_model_gpu.to('cpu')\n",
        "        torch.cuda.empty_cache()\n",
        "        embedding = output.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    return embedding\n",
        "\n",
        "# --- Data Preprocessing and PyTorch Dataset ---\n",
        "def get_smiles_tokens(smiles_string, special_tokens):\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles_string):\n",
        "        matched = False\n",
        "        for token in special_tokens:\n",
        "            if smiles_string.startswith(token, i):\n",
        "                tokens.append(token)\n",
        "                i += len(token)\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            tokens.append(smiles_string[i])\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "def smiles_to_one_hot(smiles, token_to_idx, max_len, sorted_tokens):\n",
        "    tokens = get_smiles_tokens(smiles, sorted_tokens)\n",
        "    if len(tokens) > max_len:\n",
        "        tokens = tokens[:max_len]\n",
        "    padded_tokens = tokens + ['`'] * (max_len - len(tokens))\n",
        "    one_hot_vector = np.zeros((max_len, len(token_to_idx)), dtype=np.float32)\n",
        "    for i, token in enumerate(padded_tokens):\n",
        "        if token in token_to_idx:\n",
        "            one_hot_vector[i, token_to_idx[token]] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "class SmilesProteinDataset(Dataset):\n",
        "    \"\"\"Dataset for loading SMILES and Protein sequence pairs.\"\"\"\n",
        "    def __init__(self, smiles_list, protein_list, smiles_token_dict, smiles_max_len, sorted_tokens, embedding_function):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.protein_list = protein_list\n",
        "        self.smiles_token_dict = smiles_token_dict\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.sorted_tokens = sorted_tokens\n",
        "        self.embedding_function = embedding_function\n",
        "        # Removed the protein_embeddings_cache. Embeddings will be generated on-the-fly.\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles_list[idx]\n",
        "        protein = self.protein_list[idx]\n",
        "        smiles_one_hot = smiles_to_one_hot(smiles, self.smiles_token_dict, self.smiles_max_len, self.sorted_tokens)\n",
        "\n",
        "        # Generate embedding on-the-fly\n",
        "        protein_embedding = self.embedding_function(protein)\n",
        "\n",
        "        return torch.tensor(smiles_one_hot, dtype=torch.float32), torch.tensor(protein_embedding, dtype=torch.float32)\n",
        "\n",
        "# --- Conditional VAE Model Definition ---\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, smiles_vocab_size, protein_embedding_dim, hidden_dim, latent_dim, smiles_max_len, num_layers):\n",
        "        super(ConditionalVAE, self).__init__()\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.smiles_vocab_size = smiles_vocab_size\n",
        "        self.protein_embedding_dim = protein_embedding_dim\n",
        "\n",
        "        self.encoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.encoder_protein_mlp = nn.Sequential(\n",
        "            nn.Linear(protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        self.decoder_gru_input_mlp = nn.Sequential(\n",
        "            nn.Linear(latent_dim + protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc_output = nn.Linear(hidden_dim, smiles_vocab_size)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encoder(self, smiles_one_hot, protein_embedding):\n",
        "        _, hidden_smiles = self.encoder_rnn(smiles_one_hot)\n",
        "        hidden_protein = self.encoder_protein_mlp(protein_embedding).unsqueeze(0).repeat(hidden_smiles.size(0), 1, 1)\n",
        "        combined_hidden = hidden_smiles + hidden_protein\n",
        "        final_hidden_state = combined_hidden[-1, :, :]\n",
        "        mu = self.fc_mu(final_hidden_state)\n",
        "        logvar = self.fc_logvar(final_hidden_state)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decoder(self, z, protein_embedding):\n",
        "        z_with_protein = torch.cat((z, protein_embedding), dim=1)\n",
        "        initial_hidden = self.decoder_gru_input_mlp(z_with_protein).unsqueeze(0)\n",
        "        initial_hidden = initial_hidden.repeat(self.decoder_rnn.num_layers, 1, 1)\n",
        "        decoder_input = torch.zeros(z.size(0), self.smiles_max_len, self.smiles_vocab_size).to(z.device)\n",
        "        output, _ = self.decoder_rnn(decoder_input, initial_hidden)\n",
        "        output = self.fc_output(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, smiles_one_hot, protein_embedding):\n",
        "        mu, logvar = self.encoder(smiles_one_hot, protein_embedding)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_smiles = self.decoder(z, protein_embedding)\n",
        "        return reconstructed_smiles, mu, logvar\n",
        "\n",
        "# --- Training Loop and Generation ---\n",
        "def vae_loss(recon_x, x, mu, logvar, smiles_vocab_size):\n",
        "    \"\"\"VAE loss function: BCE + KL divergence.\"\"\"\n",
        "    recon_x_flat = recon_x.view(-1, smiles_vocab_size)\n",
        "    x_flat = x.view(-1, smiles_vocab_size)\n",
        "    BCE = nn.functional.binary_cross_entropy_with_logits(recon_x_flat, x_flat, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def train_model(model, dataloader, optimizer, device, smiles_vocab_size):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    tqdm_loader = tqdm(dataloader, desc=\"Training\")\n",
        "    for smiles_oh, protein_emb in tqdm_loader:\n",
        "        smiles_oh = smiles_oh.to(device)\n",
        "        protein_emb = protein_emb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "        loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        tqdm_loader.set_postfix(batch_loss=loss.item() / smiles_oh.size(0))\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def validate_model(model, dataloader, device, smiles_vocab_size):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        tqdm_loader = tqdm(dataloader, desc=\"Validation\")\n",
        "        for smiles_oh, protein_emb in tqdm_loader:\n",
        "            smiles_oh = smiles_oh.to(device)\n",
        "            protein_emb = protein_emb.to(device)\n",
        "            reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "            loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "            total_loss += loss.item()\n",
        "            tqdm_loader.set_postfix(batch_loss=loss.item() / smiles_oh.size(0))\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def generate_new_molecules(model, smiles_token_dict, protein_seq, num_molecules, device, latent_dim, sorted_tokens):\n",
        "    model.eval()\n",
        "    idx_to_token = {v: k for k, v in smiles_token_dict.items()}\n",
        "    generated_molecules = []\n",
        "\n",
        "    protein_embedding = get_esm_embedding(protein_seq)\n",
        "    protein_embedding = torch.tensor(protein_embedding, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\nAttempting to generate {num_molecules} molecules for protein sequence...\")\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_molecules):\n",
        "            z = torch.randn(1, latent_dim).to(device)\n",
        "            generated_output = model.decoder(z, protein_embedding)\n",
        "            probabilities = nn.functional.softmax(generated_output, dim=-1)\n",
        "            predicted_indices = torch.argmax(probabilities, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "            generated_smiles = \"\"\n",
        "            for token_idx in predicted_indices:\n",
        "                token = idx_to_token.get(token_idx, '')\n",
        "                if token == '`':\n",
        "                    break\n",
        "                generated_smiles += token\n",
        "\n",
        "            mol = Chem.MolFromSmiles(generated_smiles)\n",
        "            if mol is not None:\n",
        "                print(f\"Generated molecule {i+1} (valid SMILES): {generated_smiles}\")\n",
        "            else:\n",
        "                print(f\"Generated molecule {i+1} (invalid SMILES): {generated_smiles}\")\n",
        "            generated_molecules.append(generated_smiles)\n",
        "    return generated_molecules\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    target_protein_sequence = 'MGNASNDSQSEDCETRQWLPPGESPAISSVMFSAGVLGNLIALALLARRWRGDVGCSAGRRSSLSLFHVLVTELVFTDLLGTCLISPVVLASYARNQTLVALAPESRACTYFAFAMTFFSLATMLMLFAMALERYLSIGHPYFYQRRVSRSGGLAVLPVIYAVSLLFCSLPLLDYGQYVQYCPGTWCFIRHGRTAYLQLYATLLLLLIVSVLACNFSVILNLIRMHRRSRRSRCGPSLGSGRGGPGARRRGERVSMAEETDHLILLAIMTITFAVCSLPFTIFAYMNETSSRKEKWDLQALRFLSINSIIDPWVFAILRPPVLRLMRSVLCCRISLRTQDATQTSCSTQSDASKQADL'\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_FILE_PATH)\n",
        "        smiles_list = df['SMILES'].tolist()\n",
        "        protein_list = df['Protein_Sequence'].tolist()\n",
        "        print(f\"Successfully loaded {len(smiles_list)} data points from '{CSV_FILE_PATH}'.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The data file '{CSV_FILE_PATH}' was not found.\")\n",
        "        print(\"Please ensure the file is located at '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'.\")\n",
        "        exit()\n",
        "\n",
        "    initial_count = len(smiles_list)\n",
        "    filtered_smiles = []\n",
        "    filtered_proteins = []\n",
        "    for smiles, protein in zip(smiles_list, protein_list):\n",
        "        if pd.isna(protein) or not isinstance(protein, str) or not protein.strip():\n",
        "            continue\n",
        "        if len(protein) <= MAX_PROTEIN_SEQUENCE_LEN:\n",
        "            filtered_smiles.append(smiles)\n",
        "            filtered_proteins.append(protein)\n",
        "    smiles_list = filtered_smiles\n",
        "    protein_list = filtered_proteins\n",
        "    print(f\"Filtered dataset: Retained {len(smiles_list)} rows out of {initial_count} \"\n",
        "          f\"by removing invalid protein sequences and sequences of length > {MAX_PROTEIN_SEQUENCE_LEN}.\")\n",
        "\n",
        "    full_dataset = SmilesProteinDataset(smiles_list, protein_list, SMILES_TOKEN_DICT, SMILES_MAX_LEN, sorted_tokens, get_esm_embedding)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=ESM_EMBEDDING_DIM,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        print(f\"--- Epoch {epoch+1}/{MAX_EPOCHS} ---\")\n",
        "        train_loss = train_model(model, train_dataloader, optimizer, device, len(SMILES_TOKEN_DICT))\n",
        "        val_loss = validate_model(model, val_dataloader, device, len(SMILES_TOKEN_DICT))\n",
        "        print(f\"Epoch {epoch+1}/{MAX_EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            print(f\"Validation loss improved. Saving model to {MODEL_SAVE_PATH}\")\n",
        "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Validation loss did not improve. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nTraining complete. Model saved to '{MODEL_SAVE_PATH}'.\")\n",
        "\n",
        "    best_model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=ESM_EMBEDDING_DIM,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "    generate_new_molecules(best_model, SMILES_TOKEN_DICT, target_protein_sequence, num_molecules=5, device=device, latent_dim=LATENT_DIM, sorted_tokens=sorted_tokens)"
      ],
      "metadata": {
        "id": "RouW0MFBUGT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405,
          "referenced_widgets": [
            "b0804a61ba6b4d82965f465a3dc6bf06",
            "fe3258f93ce247619679918285a66799",
            "3022c28044694e1d82b02518d299cac3",
            "4e4b04a075dd4b7ea67eee14773fa89c",
            "ce707b703853431382c4148b41daa877",
            "11e72ef15ffc458da08c2d38e7db76d6",
            "29ee71eaa16f4a6d988f4c52e2d55f34",
            "3dbadfaac2954fabaedb473aff9b65d8",
            "27282fc66e514bbc9c3aaa2887e9bf33",
            "c2a0424662c64f6183151222b362e2ca",
            "9292e62be2fe498db5cfdd1c119a4496",
            "16716f654dfc4d3eaaa97976e5c39588",
            "671b907fa5ec43628093f8050a784c3c",
            "53604a76ac784ab3b0896de227406495",
            "8d85717999cc4a7783209f0660618514",
            "e97e1a30ff5a46cdbe434a6baffbb978",
            "e7f306d9929a40159b56b163c8490d77",
            "9c32c82d212d42adb7898cc699f216c5",
            "3d41685519f84b7ba14185aaa1805ef2",
            "e233f3775f5f4e7fa71284823a54c9dc",
            "2b910cdb7dbe452c8ab2a261ac8dc3fd",
            "53ad21fa5f874e93abd14323496994bf",
            "aaab450f3cce48f78fe1cd3cae03c4f9",
            "9be9f300148e4d96ba26c54673ba84d9",
            "1ad4922d1d3d42eaa88606648f010ad5",
            "c8c05c7905034d1886303dd51faee923",
            "efc0c435d2e24fafb89b9e7a49c444ee",
            "6fd2e91a73cd4ab5b3a787048b2b2245",
            "6258dd04c20e4f2f8b38d5b345812491",
            "c77d60503bc54b0ba36ac54f2e1d6b35",
            "f346a41965fc4f90bc3d3ea55551667e",
            "d544c6a957664d4baf3a3bce0671ddc0",
            "8f21d60593004cafa8b072b584e59990",
            "601bf08e00a74bf1bf6f030481af6acb",
            "882929113fd84b669a9e22579a9b884b",
            "b4bfa13f998e4ee59ccbadc8d179f48f",
            "b8d9f2b6064d495cb588f807d5551d6c",
            "670c4e55d2c64afdacd74e303b7f0988",
            "c18313492227481f8f973e3ffafee71f",
            "857d40eb7acc471498edd3e268206877",
            "4540b2388fb442629e9d2759ac85386b",
            "2c75c8d92ae049f490d8c82e48e1e31b",
            "d6fe9f4a92104d8aaa918093aba3fd19",
            "919a2e3730f44e0290dc5654e64cd970",
            "8a06855c013c465f929ed4ca7cb3d590",
            "76bacbe4daa645d5b5c4e8bb7a9348c8",
            "26329157a95a416b8e29bbb01cbf6120",
            "69b2920073bc45bcb58a1811d9dd209b",
            "694a28fbfe7a486cb56588b56ea68d57",
            "5f145678ca04484188f899643c512e94",
            "04477de3c3084bcd9ae8d510134f5c16",
            "d73f78a7843040a5be6a1b32daf01705",
            "e8de457c319847c7bd16fd834ee1832d",
            "7ba96cbbea334126b2a6853b5d4ab4b4",
            "5dad03ba90ae4bc7b3ada5310b3359ad"
          ]
        },
        "outputId": "2fd95ec8-d6a4-43f5-9f31-1d07c596fbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Using device: cuda\n",
            "Loading ESM-2 model: esm2_t12_35M_UR50D to CPU...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0804a61ba6b4d82965f465a3dc6bf06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16716f654dfc4d3eaaa97976e5c39588"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaab450f3cce48f78fe1cd3cae03c4f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/778 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "601bf08e00a74bf1bf6f030481af6acb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/136M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a06855c013c465f929ed4ca7cb3d590"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESM model loaded successfully to CPU with embedding dimension: 480\n",
            "Successfully loaded 3046040 data points from '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'.\n",
            "Filtered dataset: Retained 2479480 rows out of 3046040 by removing invalid protein sequences and sequences of length > 1000.\n",
            "Starting training...\n",
            "--- Epoch 1/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 2/27120 [00:15<57:25:25,  7.62s/it, batch_loss=5.06e+4]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fS_LGqTIpciD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0804a61ba6b4d82965f465a3dc6bf06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe3258f93ce247619679918285a66799",
              "IPY_MODEL_3022c28044694e1d82b02518d299cac3",
              "IPY_MODEL_4e4b04a075dd4b7ea67eee14773fa89c"
            ],
            "layout": "IPY_MODEL_ce707b703853431382c4148b41daa877"
          }
        },
        "fe3258f93ce247619679918285a66799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e72ef15ffc458da08c2d38e7db76d6",
            "placeholder": "​",
            "style": "IPY_MODEL_29ee71eaa16f4a6d988f4c52e2d55f34",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3022c28044694e1d82b02518d299cac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dbadfaac2954fabaedb473aff9b65d8",
            "max": 95,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27282fc66e514bbc9c3aaa2887e9bf33",
            "value": 95
          }
        },
        "4e4b04a075dd4b7ea67eee14773fa89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2a0424662c64f6183151222b362e2ca",
            "placeholder": "​",
            "style": "IPY_MODEL_9292e62be2fe498db5cfdd1c119a4496",
            "value": " 95.0/95.0 [00:00&lt;00:00, 11.7kB/s]"
          }
        },
        "ce707b703853431382c4148b41daa877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e72ef15ffc458da08c2d38e7db76d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29ee71eaa16f4a6d988f4c52e2d55f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dbadfaac2954fabaedb473aff9b65d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27282fc66e514bbc9c3aaa2887e9bf33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2a0424662c64f6183151222b362e2ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9292e62be2fe498db5cfdd1c119a4496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16716f654dfc4d3eaaa97976e5c39588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_671b907fa5ec43628093f8050a784c3c",
              "IPY_MODEL_53604a76ac784ab3b0896de227406495",
              "IPY_MODEL_8d85717999cc4a7783209f0660618514"
            ],
            "layout": "IPY_MODEL_e97e1a30ff5a46cdbe434a6baffbb978"
          }
        },
        "671b907fa5ec43628093f8050a784c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7f306d9929a40159b56b163c8490d77",
            "placeholder": "​",
            "style": "IPY_MODEL_9c32c82d212d42adb7898cc699f216c5",
            "value": "vocab.txt: 100%"
          }
        },
        "53604a76ac784ab3b0896de227406495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d41685519f84b7ba14185aaa1805ef2",
            "max": 93,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e233f3775f5f4e7fa71284823a54c9dc",
            "value": 93
          }
        },
        "8d85717999cc4a7783209f0660618514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b910cdb7dbe452c8ab2a261ac8dc3fd",
            "placeholder": "​",
            "style": "IPY_MODEL_53ad21fa5f874e93abd14323496994bf",
            "value": " 93.0/93.0 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "e97e1a30ff5a46cdbe434a6baffbb978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f306d9929a40159b56b163c8490d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c32c82d212d42adb7898cc699f216c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d41685519f84b7ba14185aaa1805ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e233f3775f5f4e7fa71284823a54c9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b910cdb7dbe452c8ab2a261ac8dc3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ad21fa5f874e93abd14323496994bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaab450f3cce48f78fe1cd3cae03c4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9be9f300148e4d96ba26c54673ba84d9",
              "IPY_MODEL_1ad4922d1d3d42eaa88606648f010ad5",
              "IPY_MODEL_c8c05c7905034d1886303dd51faee923"
            ],
            "layout": "IPY_MODEL_efc0c435d2e24fafb89b9e7a49c444ee"
          }
        },
        "9be9f300148e4d96ba26c54673ba84d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fd2e91a73cd4ab5b3a787048b2b2245",
            "placeholder": "​",
            "style": "IPY_MODEL_6258dd04c20e4f2f8b38d5b345812491",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1ad4922d1d3d42eaa88606648f010ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c77d60503bc54b0ba36ac54f2e1d6b35",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f346a41965fc4f90bc3d3ea55551667e",
            "value": 125
          }
        },
        "c8c05c7905034d1886303dd51faee923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d544c6a957664d4baf3a3bce0671ddc0",
            "placeholder": "​",
            "style": "IPY_MODEL_8f21d60593004cafa8b072b584e59990",
            "value": " 125/125 [00:00&lt;00:00, 16.8kB/s]"
          }
        },
        "efc0c435d2e24fafb89b9e7a49c444ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd2e91a73cd4ab5b3a787048b2b2245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6258dd04c20e4f2f8b38d5b345812491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c77d60503bc54b0ba36ac54f2e1d6b35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f346a41965fc4f90bc3d3ea55551667e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d544c6a957664d4baf3a3bce0671ddc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f21d60593004cafa8b072b584e59990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "601bf08e00a74bf1bf6f030481af6acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_882929113fd84b669a9e22579a9b884b",
              "IPY_MODEL_b4bfa13f998e4ee59ccbadc8d179f48f",
              "IPY_MODEL_b8d9f2b6064d495cb588f807d5551d6c"
            ],
            "layout": "IPY_MODEL_670c4e55d2c64afdacd74e303b7f0988"
          }
        },
        "882929113fd84b669a9e22579a9b884b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c18313492227481f8f973e3ffafee71f",
            "placeholder": "​",
            "style": "IPY_MODEL_857d40eb7acc471498edd3e268206877",
            "value": "config.json: 100%"
          }
        },
        "b4bfa13f998e4ee59ccbadc8d179f48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4540b2388fb442629e9d2759ac85386b",
            "max": 778,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c75c8d92ae049f490d8c82e48e1e31b",
            "value": 778
          }
        },
        "b8d9f2b6064d495cb588f807d5551d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6fe9f4a92104d8aaa918093aba3fd19",
            "placeholder": "​",
            "style": "IPY_MODEL_919a2e3730f44e0290dc5654e64cd970",
            "value": " 778/778 [00:00&lt;00:00, 113kB/s]"
          }
        },
        "670c4e55d2c64afdacd74e303b7f0988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18313492227481f8f973e3ffafee71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "857d40eb7acc471498edd3e268206877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4540b2388fb442629e9d2759ac85386b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c75c8d92ae049f490d8c82e48e1e31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6fe9f4a92104d8aaa918093aba3fd19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "919a2e3730f44e0290dc5654e64cd970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a06855c013c465f929ed4ca7cb3d590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76bacbe4daa645d5b5c4e8bb7a9348c8",
              "IPY_MODEL_26329157a95a416b8e29bbb01cbf6120",
              "IPY_MODEL_69b2920073bc45bcb58a1811d9dd209b"
            ],
            "layout": "IPY_MODEL_694a28fbfe7a486cb56588b56ea68d57"
          }
        },
        "76bacbe4daa645d5b5c4e8bb7a9348c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f145678ca04484188f899643c512e94",
            "placeholder": "​",
            "style": "IPY_MODEL_04477de3c3084bcd9ae8d510134f5c16",
            "value": "model.safetensors: 100%"
          }
        },
        "26329157a95a416b8e29bbb01cbf6120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d73f78a7843040a5be6a1b32daf01705",
            "max": 136008798,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8de457c319847c7bd16fd834ee1832d",
            "value": 136008798
          }
        },
        "69b2920073bc45bcb58a1811d9dd209b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba96cbbea334126b2a6853b5d4ab4b4",
            "placeholder": "​",
            "style": "IPY_MODEL_5dad03ba90ae4bc7b3ada5310b3359ad",
            "value": " 136M/136M [00:01&lt;00:00, 55.6MB/s]"
          }
        },
        "694a28fbfe7a486cb56588b56ea68d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f145678ca04484188f899643c512e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04477de3c3084bcd9ae8d510134f5c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d73f78a7843040a5be6a1b32daf01705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8de457c319847c7bd16fd834ee1832d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ba96cbbea334126b2a6853b5d4ab4b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dad03ba90ae4bc7b3ada5310b3359ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}