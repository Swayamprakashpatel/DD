{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/DD/blob/main/Conditional_VAE_Drug_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9EyueZqCNYB"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgGdjLecJ31t",
        "outputId": "18e5783f-1b0e-4b58-9c5c-9e551698318c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppress RDKit warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Global constants for a comprehensive SMILES vocabulary ---\n",
        "def create_comprehensive_smiles_vocab():\n",
        "    \"\"\"\n",
        "    Creates a comprehensive SMILES token vocabulary based on the periodic table,\n",
        "    numbers, and common SMILES characters.\n",
        "    \"\"\"\n",
        "    periodic_table_elements = [\n",
        "        'H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si',\n",
        "        'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
        "        'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb',\n",
        "        'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
        "        'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho',\n",
        "        'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
        "        'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np',\n",
        "        'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg',\n",
        "        'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og'\n",
        "    ]\n",
        "    # Common SMILES single characters\n",
        "    single_char_tokens = [\n",
        "        '(', ')', '[', ']', '+', '-', '=', '#', '.', ':', '/', '\\\\',\n",
        "        'c', 'n', 'o', 's', '`', '@'\n",
        "    ]\n",
        "    # Numbers\n",
        "    numbers = [str(i) for i in range(10)]\n",
        "\n",
        "    # Combine all tokens and remove duplicates\n",
        "    all_tokens = set(periodic_table_elements + single_char_tokens + numbers)\n",
        "    # Add start and padding tokens\n",
        "    all_tokens.add('#') # Start token\n",
        "    all_tokens.add('`') # Padding token\n",
        "\n",
        "    # Sort tokens by length in descending order to handle multi-character tokens correctly\n",
        "    sorted_tokens = sorted(list(all_tokens), key=len, reverse=True)\n",
        "    # Create the dictionary\n",
        "    smiles_token_dict = {token: i for i, token in enumerate(sorted_tokens)}\n",
        "\n",
        "    return smiles_token_dict, sorted_tokens\n",
        "\n",
        "SMILES_TOKEN_DICT, sorted_tokens = create_comprehensive_smiles_vocab()\n",
        "SMILES_MAX_LEN = 500\n",
        "MAX_PROTEIN_SEQUENCE_LEN = 1000  # New constant to control max protein sequence length\n",
        "HIDDEN_DIM = 64\n",
        "LATENT_DIM = 128\n",
        "NUM_LAYERS = 2\n",
        "MAX_EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 15\n",
        "LEARNING_RATE = 1e-3\n",
        "MODEL_SAVE_PATH = 'best_model.pt'\n",
        "\n",
        "# --- Data Preprocessing and PyTorch Dataset ---\n",
        "def get_smiles_tokens(smiles_string, special_tokens):\n",
        "    \"\"\"\n",
        "    Tokenizes a SMILES string using a predefined list of special tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles_string):\n",
        "        matched = False\n",
        "        for token in special_tokens:\n",
        "            if smiles_string.startswith(token, i):\n",
        "                tokens.append(token)\n",
        "                i += len(token)\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            tokens.append(smiles_string[i])\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "def smiles_to_one_hot(smiles, token_to_idx, max_len, sorted_tokens):\n",
        "    \"\"\"Encodes a SMILES string into a one-hot vector with padding.\"\"\"\n",
        "    tokens = get_smiles_tokens(smiles, sorted_tokens)\n",
        "\n",
        "    if len(tokens) > max_len:\n",
        "        tokens = tokens[:max_len]\n",
        "\n",
        "    # Pad with padding token\n",
        "    padded_tokens = tokens + ['`'] * (max_len - len(tokens))\n",
        "\n",
        "    one_hot_vector = np.zeros((max_len, len(token_to_idx)), dtype=np.float32)\n",
        "    for i, token in enumerate(padded_tokens):\n",
        "        if token in token_to_idx:\n",
        "            one_hot_vector[i, token_to_idx[token]] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "def get_protein_embedding(seq):\n",
        "    \"\"\"\n",
        "    A simple, placeholder protein embedding function.\n",
        "    In a real-world scenario, you would use a more sophisticated method,\n",
        "    like a pre-trained protein language model (e.g., from the ProtTrans or ESM family)\n",
        "    for better performance on complex protein sequences.\n",
        "    \"\"\"\n",
        "    protein_vocab = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10,\n",
        "                     'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
        "    embedding = np.zeros(len(protein_vocab), dtype=np.float32)\n",
        "    for amino_acid in seq:\n",
        "        if amino_acid in protein_vocab:\n",
        "            embedding[protein_vocab[amino_acid]] = 1\n",
        "    return embedding\n",
        "\n",
        "class SmilesProteinDataset(Dataset):\n",
        "    \"\"\"Dataset for loading SMILES and Protein sequence pairs.\"\"\"\n",
        "    def __init__(self, smiles_list, protein_list, smiles_token_dict, smiles_max_len, sorted_tokens):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.protein_list = protein_list\n",
        "        self.smiles_token_dict = smiles_token_dict\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.sorted_tokens = sorted_tokens\n",
        "        # The protein embedding dimension is determined from the first sequence in the list\n",
        "        self.protein_embedding_dim = len(get_protein_embedding(self.protein_list[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles_list[idx]\n",
        "        protein = self.protein_list[idx]\n",
        "        smiles_one_hot = smiles_to_one_hot(smiles, self.smiles_token_dict, self.smiles_max_len, self.sorted_tokens)\n",
        "        protein_embedding = get_protein_embedding(protein)\n",
        "        return torch.tensor(smiles_one_hot, dtype=torch.float32), torch.tensor(protein_embedding, dtype=torch.float32)\n",
        "\n",
        "# --- Conditional VAE Model Definition ---\n",
        "\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, smiles_vocab_size, protein_embedding_dim, hidden_dim, latent_dim, smiles_max_len, num_layers):\n",
        "        super(ConditionalVAE, self).__init__()\n",
        "\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.smiles_vocab_size = smiles_vocab_size\n",
        "        self.protein_embedding_dim = protein_embedding_dim\n",
        "\n",
        "        # Encoder: takes smiles and protein embedding as input\n",
        "        self.encoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.encoder_protein_mlp = nn.Sequential(\n",
        "            nn.Linear(protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder: takes latent vector and protein embedding as input\n",
        "        self.decoder_gru_input_mlp = nn.Sequential(\n",
        "            nn.Linear(latent_dim + protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc_output = nn.Linear(hidden_dim, smiles_vocab_size)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick to sample from N(mu, var)\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encoder(self, smiles_one_hot, protein_embedding):\n",
        "        _, hidden_smiles = self.encoder_rnn(smiles_one_hot)\n",
        "        hidden_protein = self.encoder_protein_mlp(protein_embedding).unsqueeze(0).repeat(hidden_smiles.size(0), 1, 1)\n",
        "        combined_hidden = hidden_smiles + hidden_protein\n",
        "        final_hidden_state = combined_hidden[-1, :, :]\n",
        "        mu = self.fc_mu(final_hidden_state)\n",
        "        logvar = self.fc_logvar(final_hidden_state)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decoder(self, z, protein_embedding):\n",
        "        z_with_protein = torch.cat((z, protein_embedding), dim=1)\n",
        "        initial_hidden = self.decoder_gru_input_mlp(z_with_protein).unsqueeze(0)\n",
        "        initial_hidden = initial_hidden.repeat(self.decoder_rnn.num_layers, 1, 1)\n",
        "        decoder_input = torch.zeros(z.size(0), self.smiles_max_len, self.smiles_vocab_size).to(z.device)\n",
        "        output, _ = self.decoder_rnn(decoder_input, initial_hidden)\n",
        "        output = self.fc_output(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, smiles_one_hot, protein_embedding):\n",
        "        mu, logvar = self.encoder(smiles_one_hot, protein_embedding)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_smiles = self.decoder(z, protein_embedding)\n",
        "        return reconstructed_smiles, mu, logvar\n",
        "\n",
        "# --- Training Loop and Generation ---\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar, smiles_vocab_size):\n",
        "    \"\"\"VAE loss function: BCE + KL divergence.\"\"\"\n",
        "    # Ensure dimensions are compatible for BCE calculation\n",
        "    recon_x_flat = recon_x.view(-1, smiles_vocab_size)\n",
        "    x_flat = x.view(-1, smiles_vocab_size)\n",
        "    BCE = nn.functional.binary_cross_entropy_with_logits(recon_x_flat, x_flat, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def train_model(model, dataloader, optimizer, device, smiles_vocab_size):\n",
        "    \"\"\"Trains the VAE model for one epoch with a progress bar.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    tqdm_loader = tqdm(dataloader, desc=\"Training\")\n",
        "    for smiles_oh, protein_emb in tqdm_loader:\n",
        "        smiles_oh = smiles_oh.to(device)\n",
        "        protein_emb = protein_emb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "        loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Update the progress bar with the current batch loss\n",
        "        tqdm_loader.set_postfix(batch_loss=loss.item() / smiles_oh.size(0))\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def validate_model(model, dataloader, device, smiles_vocab_size):\n",
        "    \"\"\"Evaluates the model on the validation set.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        tqdm_loader = tqdm(dataloader, desc=\"Validation\")\n",
        "        for smiles_oh, protein_emb in tqdm_loader:\n",
        "            smiles_oh = smiles_oh.to(device)\n",
        "            protein_emb = protein_emb.to(device)\n",
        "\n",
        "            reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "            loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "            total_loss += loss.item()\n",
        "            # Update the progress bar with the current batch loss\n",
        "            tqdm_loader.set_postfix(batch_loss=loss.item() / smiles_oh.size(0))\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def generate_new_molecules(model, smiles_token_dict, protein_seq, num_molecules, device, latent_dim):\n",
        "    \"\"\"Generates and visualizes new molecules for a given protein sequence.\"\"\"\n",
        "    model.eval()\n",
        "    idx_to_token = {v: k for k, v in smiles_token_dict.items()}\n",
        "    generated_molecules = []\n",
        "\n",
        "    # Prepare the protein embedding for a single sequence\n",
        "    protein_embedding = get_protein_embedding(protein_seq)\n",
        "    protein_embedding = torch.tensor(protein_embedding, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    print(f\"\\nAttempting to generate {num_molecules} molecules for protein sequence: {protein_seq}\")\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_molecules):\n",
        "            # Sample a vector from the latent space\n",
        "            z = torch.randn(1, latent_dim).to(device)\n",
        "            # Use the decoder to generate a one-hot encoded SMILES string\n",
        "            generated_output = model.decoder(z, protein_embedding)\n",
        "\n",
        "            # Use softmax to get probabilities for each token and then select the most likely one\n",
        "            probabilities = nn.functional.softmax(generated_output, dim=-1)\n",
        "            predicted_indices = torch.argmax(probabilities, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "            generated_smiles = \"\"\n",
        "            for token_idx in predicted_indices:\n",
        "                token = idx_to_token.get(token_idx, '')\n",
        "                # Stop decoding when a padding token is encountered\n",
        "                if token == '`':\n",
        "                    break\n",
        "                generated_smiles += token\n",
        "\n",
        "            # Validate and display the generated SMILES string as an image\n",
        "            mol = Chem.MolFromSmiles(generated_smiles)\n",
        "            if mol is not None:\n",
        "                print(f\"Generated molecule (valid SMILES): {generated_smiles}\")\n",
        "                # You can't display images directly in this environment, but the code is ready for it.\n",
        "            else:\n",
        "                print(f\"Generated molecule (invalid SMILES): {generated_smiles}\")\n",
        "\n",
        "            generated_molecules.append(generated_smiles)\n",
        "\n",
        "    return generated_molecules\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Determine the device to use (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Define the path to the newly created CSV file in Google Drive\n",
        "    csv_file_path = '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'\n",
        "\n",
        "    # Define an example protein sequence to predict for\n",
        "    target_protein_sequence = 'MGNASNDSQSEDCETRQWLPPGESPAISSVMFSAGVLGNLIALALLARRWRGDVGCSAGRRSSLSLFHVLVTELVFTDLLGTCLISPVVLASYARNQTLVALAPESRACTYFAFAMTFFSLATMLMLFAMALERYLSIGHPYFYQRRVSRSGGLAVLPVIYAVSLLFCSLPLLDYGQYVQYCPGTWCFIRHGRTAYLQLYATLLLLLIVSVLACNFSVILNLIRMHRRSRRSRCGPSLGSGRGGPGARRRGERVSMAEETDHLILLAIMTITFAVCSLPFTIFAYMNETSSRKEKWDLQALRFLSINSIIDPWVFAILRPPVLRLMRSVLCCRISLRTQDATQTSCSTQSDASKQADL'\n",
        "\n",
        "    # --- Data Loading ---\n",
        "    try:\n",
        "        # Load the CSV file from the specified Google Drive path\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "        # Ensure the column names match the new dataset\n",
        "        smiles_list = df['SMILES'].tolist()\n",
        "        protein_list = df['Protein_Sequence'].tolist()\n",
        "        print(f\"Successfully loaded {len(smiles_list)} data points from '{csv_file_path}'.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The data file '{csv_file_path}' was not found.\")\n",
        "        print(\"Please ensure the file has been created by the previous script and is in the correct directory.\")\n",
        "        exit()\n",
        "\n",
        "    # --- Data Filtering ---\n",
        "    initial_count = len(smiles_list)\n",
        "    filtered_smiles = []\n",
        "    filtered_proteins = []\n",
        "    for smiles, protein in zip(smiles_list, protein_list):\n",
        "        if len(protein) <= MAX_PROTEIN_SEQUENCE_LEN:\n",
        "            filtered_smiles.append(smiles)\n",
        "            filtered_proteins.append(protein)\n",
        "\n",
        "    smiles_list = filtered_smiles\n",
        "    protein_list = filtered_proteins\n",
        "    print(f\"Filtered dataset: Retained {len(smiles_list)} rows out of {initial_count} \"\n",
        "          f\"with protein sequences of length <= {MAX_PROTEIN_SEQUENCE_LEN}.\")\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    full_dataset = SmilesProteinDataset(smiles_list, protein_list, SMILES_TOKEN_DICT, SMILES_MAX_LEN, sorted_tokens)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialize the model and optimizer\n",
        "    protein_embedding_dim = len(get_protein_embedding(target_protein_sequence))\n",
        "    model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        print(f\"--- Epoch {epoch+1}/{MAX_EPOCHS} ---\")\n",
        "        train_loss = train_model(model, train_dataloader, optimizer, device, len(SMILES_TOKEN_DICT))\n",
        "        val_loss = validate_model(model, val_dataloader, device, len(SMILES_TOKEN_DICT))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{MAX_EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Check for improvement and save the best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            print(f\"Validation loss improved. Saving model to {MODEL_SAVE_PATH}\")\n",
        "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Validation loss did not improve. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nTraining complete. Model saved to '{MODEL_SAVE_PATH}'.\")\n",
        "\n",
        "    # --- Generation Process ---\n",
        "    # We load the best model to ensure we are using the one with the best performance\n",
        "    best_model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "    # Generate new molecules using the loaded model\n",
        "    generate_new_molecules(best_model, SMILES_TOKEN_DICT, target_protein_sequence, num_molecules=5, device=device, latent_dim=LATENT_DIM)\n"
      ],
      "metadata": {
        "id": "Z0xc-fVNM-bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NEW CODE WITH PROTEIN UPDATING: To make the model more effective, we need to create a richer, more meaningful representation of the protein sequence. We can do this with the data you already have by using a technique called transfer learning. This involves using a pre-trained protein language model (PLM).\n",
        "\n",
        "#These models, like ESM or ProtT5, have been trained on millions of protein sequences and have learned a deep understanding of protein biology. Instead of a simple one-hot vector, they can transform a protein sequence into a dense numerical vector (an embedding) that captures a wealth of information about its function, structure, and evolutionary relationships.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppress RDKit warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Global constants for a comprehensive SMILES vocabulary ---\n",
        "def create_comprehensive_smiles_vocab():\n",
        "    \"\"\"\n",
        "    Creates a comprehensive SMILES token vocabulary based on the periodic table,\n",
        "    numbers, and common SMILES characters.\n",
        "    \"\"\"\n",
        "    periodic_table_elements = [\n",
        "        'H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si',\n",
        "        'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
        "        'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb',\n",
        "        'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
        "        'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho',\n",
        "        'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
        "        'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np',\n",
        "        'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg',\n",
        "        'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og'\n",
        "    ]\n",
        "    # Common SMILES single characters\n",
        "    single_char_tokens = [\n",
        "        '(', ')', '[', ']', '+', '-', '=', '#', '.', ':', '/', '\\\\',\n",
        "        'c', 'n', 'o', 's', '`', '@'\n",
        "    ]\n",
        "    # Numbers\n",
        "    numbers = [str(i) for i in range(10)]\n",
        "\n",
        "    # Combine all tokens and remove duplicates\n",
        "    all_tokens = set(periodic_table_elements + single_char_tokens + numbers)\n",
        "    # Add start and padding tokens\n",
        "    all_tokens.add('#') # Start token\n",
        "    all_tokens.add('`') # Padding token\n",
        "\n",
        "    # Sort tokens by length in descending order to handle multi-character tokens correctly\n",
        "    sorted_tokens = sorted(list(all_tokens), key=len, reverse=True)\n",
        "    # Create the dictionary\n",
        "    smiles_token_dict = {token: i for i, token in enumerate(sorted_tokens)}\n",
        "\n",
        "    return smiles_token_dict, sorted_tokens\n",
        "\n",
        "SMILES_TOKEN_DICT, sorted_tokens = create_comprehensive_smiles_vocab()\n",
        "SMILES_MAX_LEN = 500\n",
        "MAX_PROTEIN_SEQUENCE_LEN = 1000  # New constant to control max protein sequence length\n",
        "HIDDEN_DIM = 64\n",
        "LATENT_DIM = 128\n",
        "NUM_LAYERS = 2\n",
        "MAX_EPOCHS = 100\n",
        "BATCH_SIZE = 1000\n",
        "PATIENCE = 15\n",
        "LEARNING_RATE = 1e-3\n",
        "MODEL_SAVE_PATH = 'best_model.pt'\n",
        "\n",
        "# --- Data Preprocessing and PyTorch Dataset ---\n",
        "def get_smiles_tokens(smiles_string, special_tokens):\n",
        "    \"\"\"\n",
        "    Tokenizes a SMILES string using a predefined list of special tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles_string):\n",
        "        matched = False\n",
        "        for token in special_tokens:\n",
        "            if smiles_string.startswith(token, i):\n",
        "                tokens.append(token)\n",
        "                i += len(token)\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            tokens.append(smiles_string[i])\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "def smiles_to_one_hot(smiles, token_to_idx, max_len, sorted_tokens):\n",
        "    \"\"\"Encodes a SMILES string into a one-hot vector with padding.\"\"\"\n",
        "    tokens = get_smiles_tokens(smiles, sorted_tokens)\n",
        "\n",
        "    if len(tokens) > max_len:\n",
        "        tokens = tokens[:max_len]\n",
        "\n",
        "    # Pad with padding token\n",
        "    padded_tokens = tokens + ['`'] * (max_len - len(tokens))\n",
        "\n",
        "    one_hot_vector = np.zeros((max_len, len(token_to_idx)), dtype=np.float32)\n",
        "    for i, token in enumerate(padded_tokens):\n",
        "        if token in token_to_idx:\n",
        "            one_hot_vector[i, token_to_idx[token]] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "def get_protein_embedding(seq):\n",
        "    \"\"\"\n",
        "    A simple, placeholder protein embedding function.\n",
        "    In a real-world scenario, you would use a more sophisticated method,\n",
        "    like a pre-trained protein language model (e.g., from the ProtTrans or ESM family)\n",
        "    for better performance on complex protein sequences.\n",
        "    \"\"\"\n",
        "    protein_vocab = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10,\n",
        "                     'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
        "    embedding = np.zeros(len(protein_vocab), dtype=np.float32)\n",
        "    for amino_acid in seq:\n",
        "        if amino_acid in protein_vocab:\n",
        "            embedding[protein_vocab[amino_acid]] = 1\n",
        "    return embedding\n",
        "\n",
        "def get_advanced_protein_embedding(seq):\n",
        "    \"\"\"\n",
        "    A placeholder function for a more advanced protein embedding.\n",
        "\n",
        "    In a real-world application, this function would use a pre-trained\n",
        "    protein language model (PLM) like ESM-2 or ProtT5.\n",
        "\n",
        "    Example using a conceptual library call:\n",
        "\n",
        "    from transformers import T5EncoderModel, T5Tokenizer\n",
        "\n",
        "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_uniref50')\n",
        "    model = T5EncoderModel.from_pretrained('Rostlab/prot_t5_xl_uniref50')\n",
        "\n",
        "    # Tokenize and get embedding\n",
        "    encoded_input = tokenizer(seq, return_tensors='pt', max_length=1000, padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        embedding = model(**encoded_input).last_hidden_state.mean(dim=1).squeeze()\n",
        "\n",
        "    return embedding.numpy()\n",
        "\n",
        "    The dimension of the embedding would be around 1024, significantly larger\n",
        "    and more informative than the simple one-hot encoding.\n",
        "\n",
        "    For now, we'll return a placeholder vector to avoid a runtime error.\n",
        "    \"\"\"\n",
        "    # Placeholder for the advanced embedding dimension\n",
        "    ADVANCED_PROTEIN_EMBEDDING_DIM = 1024\n",
        "    return np.random.rand(ADVANCED_PROTEIN_EMBEDDING_DIM).astype(np.float32)\n",
        "\n",
        "class SmilesProteinDataset(Dataset):\n",
        "    \"\"\"Dataset for loading SMILES and Protein sequence pairs.\"\"\"\n",
        "    def __init__(self, smiles_list, protein_list, smiles_token_dict, smiles_max_len, sorted_tokens, embedding_function):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.protein_list = protein_list\n",
        "        self.smiles_token_dict = smiles_token_dict\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.sorted_tokens = sorted_tokens\n",
        "        self.embedding_function = embedding_function\n",
        "        # The protein embedding dimension is determined from the first sequence in the list\n",
        "        self.protein_embedding_dim = len(self.embedding_function(self.protein_list[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles_list[idx]\n",
        "        protein = self.protein_list[idx]\n",
        "        smiles_one_hot = smiles_to_one_hot(smiles, self.smiles_token_dict, self.smiles_max_len, self.sorted_tokens)\n",
        "        protein_embedding = self.embedding_function(protein)\n",
        "        return torch.tensor(smiles_one_hot, dtype=torch.float32), torch.tensor(protein_embedding, dtype=torch.float32)\n",
        "\n",
        "# --- Conditional VAE Model Definition ---\n",
        "\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, smiles_vocab_size, protein_embedding_dim, hidden_dim, latent_dim, smiles_max_len, num_layers):\n",
        "        super(ConditionalVAE, self).__init__()\n",
        "\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.smiles_vocab_size = smiles_vocab_size\n",
        "        self.protein_embedding_dim = protein_embedding_dim\n",
        "\n",
        "        # Encoder: takes smiles and protein embedding as input\n",
        "        self.encoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        # NOTE: This MLP now needs to take the more complex protein embedding as input\n",
        "        self.encoder_protein_mlp = nn.Sequential(\n",
        "            nn.Linear(protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder: takes latent vector and protein embedding as input\n",
        "        self.decoder_gru_input_mlp = nn.Sequential(\n",
        "            nn.Linear(latent_dim + protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc_output = nn.Linear(hidden_dim, smiles_vocab_size)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick to sample from N(mu, var)\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encoder(self, smiles_one_hot, protein_embedding):\n",
        "        _, hidden_smiles = self.encoder_rnn(smiles_one_hot)\n",
        "        # Ensure protein embedding has the correct shape for broadcasting\n",
        "        hidden_protein = self.encoder_protein_mlp(protein_embedding).unsqueeze(0).repeat(hidden_smiles.size(0), 1, 1)\n",
        "        combined_hidden = hidden_smiles + hidden_protein\n",
        "        final_hidden_state = combined_hidden[-1, :, :]\n",
        "        mu = self.fc_mu(final_hidden_state)\n",
        "        logvar = self.fc_logvar(final_hidden_state)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decoder(self, z, protein_embedding):\n",
        "        z_with_protein = torch.cat((z, protein_embedding), dim=1)\n",
        "        initial_hidden = self.decoder_gru_input_mlp(z_with_protein).unsqueeze(0)\n",
        "        initial_hidden = initial_hidden.repeat(self.decoder_rnn.num_layers, 1, 1)\n",
        "        decoder_input = torch.zeros(z.size(0), self.smiles_max_len, self.smiles_vocab_size).to(z.device)\n",
        "        output, _ = self.decoder_rnn(decoder_input, initial_hidden)\n",
        "        output = self.fc_output(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, smiles_one_hot, protein_embedding):\n",
        "        mu, logvar = self.encoder(smiles_one_hot, protein_embedding)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_smiles = self.decoder(z, protein_embedding)\n",
        "        return reconstructed_smiles, mu, logvar\n",
        "\n",
        "# --- Training Loop and Generation ---\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar, smiles_vocab_size):\n",
        "    \"\"\"VAE loss function: BCE + KL divergence.\"\"\"\n",
        "    # Ensure dimensions are compatible for BCE calculation\n",
        "    recon_x_flat = recon_x.view(-1, smiles_vocab_size)\n",
        "    x_flat = x.view(-1, smiles_vocab_size)\n",
        "    BCE = nn.functional.binary_cross_entropy_with_logits(recon_x_flat, x_flat, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def train_model(model, dataloader, optimizer, device, smiles_vocab_size):\n",
        "    \"\"\"Trains the VAE model for one epoch with a progress bar.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    tqdm_loader = tqdm(dataloader, desc=\"Training\")\n",
        "    for smiles_oh, protein_emb in tqdm_loader:\n",
        "        smiles_oh = smiles_oh.to(device)\n",
        "        protein_emb = protein_emb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "        loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Update the progress bar with the current batch loss\n",
        "        tqdm_loader.set_postfix(batch_loss=loss.item() / smiles_oh.size(0))\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def validate_model(model, dataloader, device, smiles_vocab_size):\n",
        "    \"\"\"Evaluates the model on the validation set.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        tqdm_loader = tqdm(dataloader, desc=\"Validation\")\n",
        "        for smiles_oh, protein_emb in tqdm_loader:\n",
        "            smiles_oh = smiles_oh.to(device)\n",
        "            protein_emb = protein_emb.to(device)\n",
        "\n",
        "            reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "            loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "            total_loss += loss.item()\n",
        "            # Update the progress bar with the current batch loss\n",
        "            tqdm_loader.set_postfix(batch_loss=loss.item() / smiles_oh.size(0))\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def generate_new_molecules(model, smiles_token_dict, protein_seq, num_molecules, device, latent_dim):\n",
        "    \"\"\"Generates and visualizes new molecules for a given protein sequence.\"\"\"\n",
        "    model.eval()\n",
        "    idx_to_token = {v: k for k, v in smiles_token_dict.items()}\n",
        "    generated_molecules = []\n",
        "\n",
        "    # Prepare the protein embedding for a single sequence\n",
        "    # NOTE: We now use the advanced embedding function here too\n",
        "    protein_embedding = get_advanced_protein_embedding(protein_seq)\n",
        "    protein_embedding = torch.tensor(protein_embedding, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    print(f\"\\nAttempting to generate {num_molecules} molecules for protein sequence: {protein_seq}\")\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_molecules):\n",
        "            # Sample a vector from the latent space\n",
        "            z = torch.randn(1, latent_dim).to(device)\n",
        "            # Use the decoder to generate a one-hot encoded SMILES string\n",
        "            generated_output = model.decoder(z, protein_embedding)\n",
        "\n",
        "            # Use softmax to get probabilities for each token and then select the most likely one\n",
        "            probabilities = nn.functional.softmax(generated_output, dim=-1)\n",
        "            predicted_indices = torch.argmax(probabilities, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "            generated_smiles = \"\"\n",
        "            for token_idx in predicted_indices:\n",
        "                token = idx_to_token.get(token_idx, '')\n",
        "                # Stop decoding when a padding token is encountered\n",
        "                if token == '`':\n",
        "                    break\n",
        "                generated_smiles += token\n",
        "\n",
        "            # Validate and display the generated SMILES string as an image\n",
        "            mol = Chem.MolFromSmiles(generated_smiles)\n",
        "            if mol is not None:\n",
        "                print(f\"Generated molecule (valid SMILES): {generated_smiles}\")\n",
        "                # You can't display images directly in this environment, but the code is ready for it.\n",
        "            else:\n",
        "                print(f\"Generated molecule (invalid SMILES): {generated_smiles}\")\n",
        "\n",
        "            generated_molecules.append(generated_smiles)\n",
        "\n",
        "    return generated_molecules\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Determine the device to use (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Define the path to the newly created CSV file in Google Drive\n",
        "    csv_file_path = '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'\n",
        "\n",
        "    # Define an example protein sequence to predict for\n",
        "    target_protein_sequence = 'MGNASNDSQSEDCETRQWLPPGESPAISSVMFSAGVLGNLIALALLARRWRGDVGCSAGRRSSLSLFHVLVTELVFTDLLGTCLISPVVLASYARNQTLVALAPESRACTYFAFAMTFFSLATMLMLFAMALERYLSIGHPYFYQRRVSRSGGLAVLPVIYAVSLLFCSLPLLDYGQYVQYCPGTWCFIRHGRTAYLQLYATLLLLLIVSVLACNFSVILNLIRMHRRSRRSRCGPSLGSGRGGPGARRRGERVSMAEETDHLILLAIMTITFAVCSLPFTIFAYMNETSSRKEKWDLQALRFLSINSIIDPWVFAILRPPVLRLMRSVLCCRISLRTQDATQTSCSTQSDASKQADL'\n",
        "\n",
        "    # --- Data Loading ---\n",
        "    try:\n",
        "        # Load the CSV file from the specified Google Drive path\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "        # Ensure the column names match the new dataset\n",
        "        smiles_list = df['SMILES'].tolist()\n",
        "        protein_list = df['Protein_Sequence'].tolist()\n",
        "        print(f\"Successfully loaded {len(smiles_list)} data points from '{csv_file_path}'.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The data file '{csv_file_path}' was not found.\")\n",
        "        print(\"Please ensure the file has been created by the previous script and is in the correct directory.\")\n",
        "        exit()\n",
        "\n",
        "    # --- Data Filtering ---\n",
        "    initial_count = len(smiles_list)\n",
        "    filtered_smiles = []\n",
        "    filtered_proteins = []\n",
        "    for smiles, protein in zip(smiles_list, protein_list):\n",
        "        # Filter out rows with missing or invalid protein sequences\n",
        "        if pd.isna(protein) or not isinstance(protein, str) or not protein.strip():\n",
        "            continue\n",
        "        # Then, apply the length filter\n",
        "        if len(protein) <= MAX_PROTEIN_SEQUENCE_LEN:\n",
        "            filtered_smiles.append(smiles)\n",
        "            filtered_proteins.append(protein)\n",
        "\n",
        "    smiles_list = filtered_smiles\n",
        "    protein_list = filtered_proteins\n",
        "    print(f\"Filtered dataset: Retained {len(smiles_list)} rows out of {initial_count} \"\n",
        "          f\"by removing invalid protein sequences and sequences of length > {MAX_PROTEIN_SEQUENCE_LEN}.\")\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    # NOTE: We now pass the advanced embedding function to the dataset\n",
        "    full_dataset = SmilesProteinDataset(smiles_list, protein_list, SMILES_TOKEN_DICT, SMILES_MAX_LEN, sorted_tokens, get_advanced_protein_embedding)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialize the model and optimizer\n",
        "    # NOTE: The protein embedding dimension is now dynamic based on the advanced embedding model\n",
        "    protein_embedding_dim = full_dataset.protein_embedding_dim\n",
        "    model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        print(f\"--- Epoch {epoch+1}/{MAX_EPOCHS} ---\")\n",
        "        train_loss = train_model(model, train_dataloader, optimizer, device, len(SMILES_TOKEN_DICT))\n",
        "        val_loss = validate_model(model, val_dataloader, device, len(SMILES_TOKEN_DICT))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{MAX_EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Check for improvement and save the best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            print(f\"Validation loss improved. Saving model to {MODEL_SAVE_PATH}\")\n",
        "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Validation loss did not improve. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nTraining complete. Model saved to '{MODEL_SAVE_PATH}'.\")\n",
        "\n",
        "    # --- Generation Process ---\n",
        "    # We load the best model to ensure we are using the one with the best performance\n",
        "    best_model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "    # Generate new molecules using the loaded model\n",
        "    generate_new_molecules(best_model, SMILES_TOKEN_DICT, target_protein_sequence, num_molecules=5, device=device, latent_dim=LATENT_DIM)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "NtiRScrQSfZ0",
        "outputId": "900f50aa-add6-425e-9431-b97b4ef19d3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Successfully loaded 3046040 data points from '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'.\n",
            "Filtered dataset: Retained 2479480 rows out of 3046040 by removing invalid protein sequences and sequences of length > 1000.\n",
            "Starting training...\n",
            "--- Epoch 1/100 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 1736/1736 [42:37<00:00,  1.47s/it, batch_loss=255]\n",
            "Validation: 100%|| 744/744 [17:33<00:00,  1.42s/it, batch_loss=279]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Train Loss: 846.0233, Validation Loss: 293.7617\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 2/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 1736/1736 [42:36<00:00,  1.47s/it, batch_loss=228]\n",
            "Validation: 100%|| 744/744 [17:35<00:00,  1.42s/it, batch_loss=204]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100, Train Loss: 223.1131, Validation Loss: 215.4699\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 3/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 1736/1736 [42:39<00:00,  1.47s/it, batch_loss=213]\n",
            "Validation:  24%|       | 180/744 [04:15<13:20,  1.42s/it, batch_loss=208]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2592900638.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- Epoch {epoch+1}/{MAX_EPOCHS} ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSMILES_TOKEN_DICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSMILES_TOKEN_DICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{MAX_EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2592900638.py\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(model, dataloader, device, smiles_vocab_size)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mtqdm_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msmiles_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_emb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0msmiles_oh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmiles_oh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mprotein_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotein_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2592900638.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0msmiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mprotein\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotein_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0msmiles_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmiles_to_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_token_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mprotein_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2592900638.py\u001b[0m in \u001b[0;36msmiles_to_one_hot\u001b[0;34m(smiles, token_to_idx, max_len, sorted_tokens)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmiles_to_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m\"\"\"Encodes a SMILES string into a one-hot vector with padding.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_smiles_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2592900638.py\u001b[0m in \u001b[0;36mget_smiles_tokens\u001b[0;34m(smiles_string, special_tokens)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mmatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspecial_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msmiles_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RouW0MFBUGT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}