{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/DD/blob/main/Conditional_VAE_Drug_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9EyueZqCNYB",
        "outputId": "b4f0dd18-e778-42f3-d265-17cd44a65f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.3.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.3.5-cp312-cp312-manylinux_2_28_x86_64.whl (36.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.3.5\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#All Periodic Table Elements in Tokeninzation Character\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppress RDKit warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Global constants for a comprehensive SMILES vocabulary ---\n",
        "def create_comprehensive_smiles_vocab():\n",
        "    \"\"\"\n",
        "    Creates a comprehensive SMILES token vocabulary based on the periodic table,\n",
        "    numbers, and common SMILES characters.\n",
        "    \"\"\"\n",
        "    periodic_table_elements = [\n",
        "        'H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si',\n",
        "        'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
        "        'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb',\n",
        "        'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
        "        'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho',\n",
        "        'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
        "        'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np',\n",
        "        'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg',\n",
        "        'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og'\n",
        "    ]\n",
        "    # Common SMILES single characters\n",
        "    single_char_tokens = [\n",
        "        '(', ')', '[', ']', '+', '-', '=', '#', '.', ':', '/', '\\\\',\n",
        "        'c', 'n', 'o', 's', '`', '@'\n",
        "    ]\n",
        "    # Numbers\n",
        "    numbers = [str(i) for i in range(10)]\n",
        "\n",
        "    # Combine all tokens and remove duplicates\n",
        "    all_tokens = set(periodic_table_elements + single_char_tokens + numbers)\n",
        "    # Add start and padding tokens\n",
        "    all_tokens.add('#') # Start token\n",
        "    all_tokens.add('`') # Padding token\n",
        "\n",
        "    # Sort tokens by length in descending order to handle multi-character tokens correctly\n",
        "    sorted_tokens = sorted(list(all_tokens), key=len, reverse=True)\n",
        "    # Create the dictionary\n",
        "    smiles_token_dict = {token: i for i, token in enumerate(sorted_tokens)}\n",
        "\n",
        "    return smiles_token_dict, sorted_tokens\n",
        "\n",
        "SMILES_TOKEN_DICT, sorted_tokens = create_comprehensive_smiles_vocab()\n",
        "SMILES_MAX_LEN = 1000\n",
        "HIDDEN_DIM = 256\n",
        "LATENT_DIM = 64\n",
        "NUM_LAYERS = 2\n",
        "MAX_EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 15\n",
        "LEARNING_RATE = 1e-3\n",
        "MODEL_SAVE_PATH = 'best_model.pt'\n",
        "\n",
        "# --- Data Preprocessing and PyTorch Dataset ---\n",
        "def get_smiles_tokens(smiles_string, special_tokens):\n",
        "    \"\"\"\n",
        "    Tokenizes a SMILES string using a predefined list of special tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles_string):\n",
        "        matched = False\n",
        "        for token in special_tokens:\n",
        "            if smiles_string.startswith(token, i):\n",
        "                tokens.append(token)\n",
        "                i += len(token)\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            tokens.append(smiles_string[i])\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "def smiles_to_one_hot(smiles, token_to_idx, max_len, sorted_tokens):\n",
        "    \"\"\"Encodes a SMILES string into a one-hot vector with padding.\"\"\"\n",
        "    tokens = get_smiles_tokens(smiles, sorted_tokens)\n",
        "\n",
        "    if len(tokens) > max_len:\n",
        "        tokens = tokens[:max_len]\n",
        "\n",
        "    # Pad with padding token\n",
        "    padded_tokens = tokens + ['`'] * (max_len - len(tokens))\n",
        "\n",
        "    one_hot_vector = np.zeros((max_len, len(token_to_idx)), dtype=np.float32)\n",
        "    for i, token in enumerate(padded_tokens):\n",
        "        if token in token_to_idx:\n",
        "            one_hot_vector[i, token_to_idx[token]] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "def get_protein_embedding(seq):\n",
        "    \"\"\"\n",
        "    A simple, placeholder protein embedding function.\n",
        "    In a real-world scenario, you would use a more sophisticated method,\n",
        "    like a pre-trained protein language model (e.g., from the ProtTrans or ESM family)\n",
        "    for better performance on complex protein sequences.\n",
        "    \"\"\"\n",
        "    protein_vocab = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10,\n",
        "                     'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
        "    embedding = np.zeros(len(protein_vocab), dtype=np.float32)\n",
        "    for amino_acid in seq:\n",
        "        if amino_acid in protein_vocab:\n",
        "            embedding[protein_vocab[amino_acid]] = 1\n",
        "    return embedding\n",
        "\n",
        "class SmilesProteinDataset(Dataset):\n",
        "    \"\"\"Dataset for loading SMILES and Protein sequence pairs.\"\"\"\n",
        "    def __init__(self, smiles_list, protein_list, smiles_token_dict, smiles_max_len, sorted_tokens):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.protein_list = protein_list\n",
        "        self.smiles_token_dict = smiles_token_dict\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.sorted_tokens = sorted_tokens\n",
        "        # The protein embedding dimension is determined from the first sequence in the list\n",
        "        self.protein_embedding_dim = len(get_protein_embedding(self.protein_list[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles_list[idx]\n",
        "        protein = self.protein_list[idx]\n",
        "        smiles_one_hot = smiles_to_one_hot(smiles, self.smiles_token_dict, self.smiles_max_len, self.sorted_tokens)\n",
        "        protein_embedding = get_protein_embedding(protein)\n",
        "        return torch.tensor(smiles_one_hot, dtype=torch.float32), torch.tensor(protein_embedding, dtype=torch.float32)\n",
        "\n",
        "# --- Conditional VAE Model Definition ---\n",
        "\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, smiles_vocab_size, protein_embedding_dim, hidden_dim, latent_dim, smiles_max_len, num_layers):\n",
        "        super(ConditionalVAE, self).__init__()\n",
        "\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.smiles_vocab_size = smiles_vocab_size\n",
        "        self.protein_embedding_dim = protein_embedding_dim\n",
        "\n",
        "        # Encoder: takes smiles and protein embedding as input\n",
        "        self.encoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.encoder_protein_mlp = nn.Sequential(\n",
        "            nn.Linear(protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder: takes latent vector and protein embedding as input\n",
        "        self.decoder_gru_input_mlp = nn.Sequential(\n",
        "            nn.Linear(latent_dim + protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc_output = nn.Linear(hidden_dim, smiles_vocab_size)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick to sample from N(mu, var)\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encoder(self, smiles_one_hot, protein_embedding):\n",
        "        _, hidden_smiles = self.encoder_rnn(smiles_one_hot)\n",
        "        hidden_protein = self.encoder_protein_mlp(protein_embedding).unsqueeze(0).repeat(hidden_smiles.size(0), 1, 1)\n",
        "        combined_hidden = hidden_smiles + hidden_protein\n",
        "        final_hidden_state = combined_hidden[-1, :, :]\n",
        "        mu = self.fc_mu(final_hidden_state)\n",
        "        logvar = self.fc_logvar(final_hidden_state)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decoder(self, z, protein_embedding):\n",
        "        z_with_protein = torch.cat((z, protein_embedding), dim=1)\n",
        "        initial_hidden = self.decoder_gru_input_mlp(z_with_protein).unsqueeze(0)\n",
        "        initial_hidden = initial_hidden.repeat(self.decoder_rnn.num_layers, 1, 1)\n",
        "        decoder_input = torch.zeros(z.size(0), self.smiles_max_len, self.smiles_vocab_size).to(z.device)\n",
        "        output, _ = self.decoder_rnn(decoder_input, initial_hidden)\n",
        "        output = self.fc_output(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, smiles_one_hot, protein_embedding):\n",
        "        mu, logvar = self.encoder(smiles_one_hot, protein_embedding)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_smiles = self.decoder(z, protein_embedding)\n",
        "        return reconstructed_smiles, mu, logvar\n",
        "\n",
        "# --- Training Loop and Generation ---\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar, smiles_vocab_size):\n",
        "    \"\"\"VAE loss function: BCE + KL divergence.\"\"\"\n",
        "    # Ensure dimensions are compatible for BCE calculation\n",
        "    recon_x_flat = recon_x.view(-1, smiles_vocab_size)\n",
        "    x_flat = x.view(-1, smiles_vocab_size)\n",
        "    BCE = nn.functional.binary_cross_entropy_with_logits(recon_x_flat, x_flat, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def train_model(model, dataloader, optimizer, device, smiles_vocab_size):\n",
        "    \"\"\"Trains the VAE model for one epoch with a progress bar.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for smiles_oh, protein_emb in tqdm(dataloader, desc=\"Training\"):\n",
        "        smiles_oh = smiles_oh.to(device)\n",
        "        protein_emb = protein_emb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "        loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def validate_model(model, dataloader, device, smiles_vocab_size):\n",
        "    \"\"\"Evaluates the model on the validation set.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for smiles_oh, protein_emb in tqdm(dataloader, desc=\"Validation\"):\n",
        "            smiles_oh = smiles_oh.to(device)\n",
        "            protein_emb = protein_emb.to(device)\n",
        "\n",
        "            reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "            loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def generate_new_molecules(model, smiles_token_dict, protein_seq, num_molecules, device, latent_dim):\n",
        "    \"\"\"Generates and visualizes new molecules for a given protein sequence.\"\"\"\n",
        "    model.eval()\n",
        "    idx_to_token = {v: k for k, v in smiles_token_dict.items()}\n",
        "    generated_molecules = []\n",
        "\n",
        "    # Prepare the protein embedding for a single sequence\n",
        "    protein_embedding = get_protein_embedding(protein_seq)\n",
        "    protein_embedding = torch.tensor(protein_embedding, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    print(f\"\\nAttempting to generate {num_molecules} molecules for protein sequence: {protein_seq}\")\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_molecules):\n",
        "            # Sample a vector from the latent space\n",
        "            z = torch.randn(1, latent_dim).to(device)\n",
        "            # Use the decoder to generate a one-hot encoded SMILES string\n",
        "            generated_output = model.decoder(z, protein_embedding)\n",
        "\n",
        "            # Use softmax to get probabilities for each token and then select the most likely one\n",
        "            probabilities = nn.functional.softmax(generated_output, dim=-1)\n",
        "            predicted_indices = torch.argmax(probabilities, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "            generated_smiles = \"\"\n",
        "            for token_idx in predicted_indices:\n",
        "                token = idx_to_token.get(token_idx, '')\n",
        "                # Stop decoding when a padding token is encountered\n",
        "                if token == '`':\n",
        "                    break\n",
        "                generated_smiles += token\n",
        "\n",
        "            # Validate and display the generated SMILES string as an image\n",
        "            mol = Chem.MolFromSmiles(generated_smiles)\n",
        "            if mol is not None:\n",
        "                print(f\"Generated molecule (valid SMILES): {generated_smiles}\")\n",
        "                img = MolToImage(mol)\n",
        "                display(img)\n",
        "            else:\n",
        "                print(f\"Generated molecule (invalid SMILES): {generated_smiles}\")\n",
        "\n",
        "            generated_molecules.append(generated_smiles)\n",
        "\n",
        "    return generated_molecules\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Determine the device to use (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Define an example protein sequence to predict for\n",
        "    target_protein_sequence = 'MGNASNDSQSEDCETRQWLPPGESPAISSVMFSAGVLGNLIALALLARRWRGDVGCSAGRRSSLSLFHVLVTELVFTDLLGTCLISPVVLASYARNQTLVALAPESRACTYFAFAMTFFSLATMLMLFAMALERYLSIGHPYFYQRRVSRSGGLAVLPVIYAVSLLFCSLPLLDYGQYVQYCPGTWCFIRHGRTAYLQLYATLLLLLIVSVLACNFSVILNLIRMHRRSRRSRCGPSLGSGRGGPGARRRGERVSMAEETDHLILLAIMTITFAVCSLPFTIFAYMNETSSRKEKWDLQALRFLSINSIIDPWVFAILRPPVLRLMRSVLCCRISLRTQDATQTSCSTQSDASKQADL'\n",
        "\n",
        "    # --- Training Process ---\n",
        "    try:\n",
        "        df = pd.read_csv('final_output_15_2_25.csv')\n",
        "        smiles_list = df['SMILES'].tolist()\n",
        "        protein_list = df['TARGET_SEQUENCE'].tolist()\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: The data file 'final_output_15_2_25.csv' was not found. Please ensure it is uploaded.\")\n",
        "        exit()\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    full_dataset = SmilesProteinDataset(smiles_list, protein_list, SMILES_TOKEN_DICT, SMILES_MAX_LEN, sorted_tokens)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialize the model and optimizer\n",
        "    protein_embedding_dim = len(get_protein_embedding(target_protein_sequence))\n",
        "    model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        print(f\"--- Epoch {epoch+1}/{MAX_EPOCHS} ---\")\n",
        "        train_loss = train_model(model, train_dataloader, optimizer, device, len(SMILES_TOKEN_DICT))\n",
        "        val_loss = validate_model(model, val_dataloader, device, len(SMILES_TOKEN_DICT))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{MAX_EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Check for improvement and save the best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            print(f\"Validation loss improved. Saving model to {MODEL_SAVE_PATH}\")\n",
        "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Validation loss did not improve. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nTraining complete. Model saved to '{MODEL_SAVE_PATH}'.\")\n",
        "\n",
        "    # --- Generation Process ---\n",
        "    # We load the best model to ensure we are using the one with the best performance\n",
        "    best_model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "    # Generate new molecules using the loaded model\n",
        "    generate_new_molecules(best_model, SMILES_TOKEN_DICT, target_protein_sequence, num_molecules=5, device=device, latent_dim=LATENT_DIM)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjr6Tmoww0wF",
        "outputId": "2e67e66d-9151-45e1-947a-7a06982d1915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting training...\n",
            "--- Epoch 1/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  63%|██████▎   | 216/344 [00:48<00:28,  4.54it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}