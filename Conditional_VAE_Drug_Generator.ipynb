{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/DD/blob/main/Conditional_VAE_Drug_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9EyueZqCNYB",
        "outputId": "4bb89fb5-a909-4afb-9522-f1eb40e99b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#All Periodic Table Elements in Tokeninzation Character\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppress RDKit warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Global constants for a comprehensive SMILES vocabulary ---\n",
        "def create_comprehensive_smiles_vocab():\n",
        "    \"\"\"\n",
        "    Creates a comprehensive SMILES token vocabulary based on the periodic table,\n",
        "    numbers, and common SMILES characters.\n",
        "    \"\"\"\n",
        "    periodic_table_elements = [\n",
        "        'H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si',\n",
        "        'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
        "        'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb',\n",
        "        'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
        "        'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho',\n",
        "        'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
        "        'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np',\n",
        "        'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg',\n",
        "        'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og'\n",
        "    ]\n",
        "    # Common SMILES single characters\n",
        "    single_char_tokens = [\n",
        "        '(', ')', '[', ']', '+', '-', '=', '#', '.', ':', '/', '\\\\',\n",
        "        'c', 'n', 'o', 's', '`', '@'\n",
        "    ]\n",
        "    # Numbers\n",
        "    numbers = [str(i) for i in range(10)]\n",
        "\n",
        "    # Combine all tokens and remove duplicates\n",
        "    all_tokens = set(periodic_table_elements + single_char_tokens + numbers)\n",
        "    # Add start and padding tokens\n",
        "    all_tokens.add('#') # Start token\n",
        "    all_tokens.add('`') # Padding token\n",
        "\n",
        "    # Sort tokens by length in descending order to handle multi-character tokens correctly\n",
        "    sorted_tokens = sorted(list(all_tokens), key=len, reverse=True)\n",
        "    # Create the dictionary\n",
        "    smiles_token_dict = {token: i for i, token in enumerate(sorted_tokens)}\n",
        "\n",
        "    return smiles_token_dict, sorted_tokens\n",
        "\n",
        "SMILES_TOKEN_DICT, sorted_tokens = create_comprehensive_smiles_vocab()\n",
        "SMILES_MAX_LEN = 1000\n",
        "HIDDEN_DIM = 64\n",
        "LATENT_DIM = 128\n",
        "NUM_LAYERS = 2\n",
        "MAX_EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 15\n",
        "LEARNING_RATE = 1e-3\n",
        "MODEL_SAVE_PATH = 'best_model.pt'\n",
        "\n",
        "# --- Data Preprocessing and PyTorch Dataset ---\n",
        "def get_smiles_tokens(smiles_string, special_tokens):\n",
        "    \"\"\"\n",
        "    Tokenizes a SMILES string using a predefined list of special tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles_string):\n",
        "        matched = False\n",
        "        for token in special_tokens:\n",
        "            if smiles_string.startswith(token, i):\n",
        "                tokens.append(token)\n",
        "                i += len(token)\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            tokens.append(smiles_string[i])\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "def smiles_to_one_hot(smiles, token_to_idx, max_len, sorted_tokens):\n",
        "    \"\"\"Encodes a SMILES string into a one-hot vector with padding.\"\"\"\n",
        "    tokens = get_smiles_tokens(smiles, sorted_tokens)\n",
        "\n",
        "    if len(tokens) > max_len:\n",
        "        tokens = tokens[:max_len]\n",
        "\n",
        "    # Pad with padding token\n",
        "    padded_tokens = tokens + ['`'] * (max_len - len(tokens))\n",
        "\n",
        "    one_hot_vector = np.zeros((max_len, len(token_to_idx)), dtype=np.float32)\n",
        "    for i, token in enumerate(padded_tokens):\n",
        "        if token in token_to_idx:\n",
        "            one_hot_vector[i, token_to_idx[token]] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "def get_protein_embedding(seq):\n",
        "    \"\"\"\n",
        "    A simple, placeholder protein embedding function.\n",
        "    In a real-world scenario, you would use a more sophisticated method,\n",
        "    like a pre-trained protein language model (e.g., from the ProtTrans or ESM family)\n",
        "    for better performance on complex protein sequences.\n",
        "    \"\"\"\n",
        "    protein_vocab = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10,\n",
        "                     'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
        "    embedding = np.zeros(len(protein_vocab), dtype=np.float32)\n",
        "    for amino_acid in seq:\n",
        "        if amino_acid in protein_vocab:\n",
        "            embedding[protein_vocab[amino_acid]] = 1\n",
        "    return embedding\n",
        "\n",
        "class SmilesProteinDataset(Dataset):\n",
        "    \"\"\"Dataset for loading SMILES and Protein sequence pairs.\"\"\"\n",
        "    def __init__(self, smiles_list, protein_list, smiles_token_dict, smiles_max_len, sorted_tokens):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.protein_list = protein_list\n",
        "        self.smiles_token_dict = smiles_token_dict\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.sorted_tokens = sorted_tokens\n",
        "        # The protein embedding dimension is determined from the first sequence in the list\n",
        "        self.protein_embedding_dim = len(get_protein_embedding(self.protein_list[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles_list[idx]\n",
        "        protein = self.protein_list[idx]\n",
        "        smiles_one_hot = smiles_to_one_hot(smiles, self.smiles_token_dict, self.smiles_max_len, self.sorted_tokens)\n",
        "        protein_embedding = get_protein_embedding(protein)\n",
        "        return torch.tensor(smiles_one_hot, dtype=torch.float32), torch.tensor(protein_embedding, dtype=torch.float32)\n",
        "\n",
        "# --- Conditional VAE Model Definition ---\n",
        "\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, smiles_vocab_size, protein_embedding_dim, hidden_dim, latent_dim, smiles_max_len, num_layers):\n",
        "        super(ConditionalVAE, self).__init__()\n",
        "\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.smiles_vocab_size = smiles_vocab_size\n",
        "        self.protein_embedding_dim = protein_embedding_dim\n",
        "\n",
        "        # Encoder: takes smiles and protein embedding as input\n",
        "        self.encoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.encoder_protein_mlp = nn.Sequential(\n",
        "            nn.Linear(protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder: takes latent vector and protein embedding as input\n",
        "        self.decoder_gru_input_mlp = nn.Sequential(\n",
        "            nn.Linear(latent_dim + protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc_output = nn.Linear(hidden_dim, smiles_vocab_size)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick to sample from N(mu, var)\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encoder(self, smiles_one_hot, protein_embedding):\n",
        "        _, hidden_smiles = self.encoder_rnn(smiles_one_hot)\n",
        "        hidden_protein = self.encoder_protein_mlp(protein_embedding).unsqueeze(0).repeat(hidden_smiles.size(0), 1, 1)\n",
        "        combined_hidden = hidden_smiles + hidden_protein\n",
        "        final_hidden_state = combined_hidden[-1, :, :]\n",
        "        mu = self.fc_mu(final_hidden_state)\n",
        "        logvar = self.fc_logvar(final_hidden_state)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decoder(self, z, protein_embedding):\n",
        "        z_with_protein = torch.cat((z, protein_embedding), dim=1)\n",
        "        initial_hidden = self.decoder_gru_input_mlp(z_with_protein).unsqueeze(0)\n",
        "        initial_hidden = initial_hidden.repeat(self.decoder_rnn.num_layers, 1, 1)\n",
        "        decoder_input = torch.zeros(z.size(0), self.smiles_max_len, self.smiles_vocab_size).to(z.device)\n",
        "        output, _ = self.decoder_rnn(decoder_input, initial_hidden)\n",
        "        output = self.fc_output(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, smiles_one_hot, protein_embedding):\n",
        "        mu, logvar = self.encoder(smiles_one_hot, protein_embedding)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_smiles = self.decoder(z, protein_embedding)\n",
        "        return reconstructed_smiles, mu, logvar\n",
        "\n",
        "# --- Training Loop and Generation ---\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar, smiles_vocab_size):\n",
        "    \"\"\"VAE loss function: BCE + KL divergence.\"\"\"\n",
        "    # Ensure dimensions are compatible for BCE calculation\n",
        "    recon_x_flat = recon_x.view(-1, smiles_vocab_size)\n",
        "    x_flat = x.view(-1, smiles_vocab_size)\n",
        "    BCE = nn.functional.binary_cross_entropy_with_logits(recon_x_flat, x_flat, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def train_model(model, dataloader, optimizer, device, smiles_vocab_size):\n",
        "    \"\"\"Trains the VAE model for one epoch with a progress bar.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for smiles_oh, protein_emb in tqdm(dataloader, desc=\"Training\"):\n",
        "        smiles_oh = smiles_oh.to(device)\n",
        "        protein_emb = protein_emb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "        loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def validate_model(model, dataloader, device, smiles_vocab_size):\n",
        "    \"\"\"Evaluates the model on the validation set.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for smiles_oh, protein_emb in tqdm(dataloader, desc=\"Validation\"):\n",
        "            smiles_oh = smiles_oh.to(device)\n",
        "            protein_emb = protein_emb.to(device)\n",
        "\n",
        "            reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "            loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def generate_new_molecules(model, smiles_token_dict, protein_seq, num_molecules, device, latent_dim):\n",
        "    \"\"\"Generates and visualizes new molecules for a given protein sequence.\"\"\"\n",
        "    model.eval()\n",
        "    idx_to_token = {v: k for k, v in smiles_token_dict.items()}\n",
        "    generated_molecules = []\n",
        "\n",
        "    # Prepare the protein embedding for a single sequence\n",
        "    protein_embedding = get_protein_embedding(protein_seq)\n",
        "    protein_embedding = torch.tensor(protein_embedding, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    print(f\"\\nAttempting to generate {num_molecules} molecules for protein sequence: {protein_seq}\")\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_molecules):\n",
        "            # Sample a vector from the latent space\n",
        "            z = torch.randn(1, latent_dim).to(device)\n",
        "            # Use the decoder to generate a one-hot encoded SMILES string\n",
        "            generated_output = model.decoder(z, protein_embedding)\n",
        "\n",
        "            # Use softmax to get probabilities for each token and then select the most likely one\n",
        "            probabilities = nn.functional.softmax(generated_output, dim=-1)\n",
        "            predicted_indices = torch.argmax(probabilities, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "            generated_smiles = \"\"\n",
        "            for token_idx in predicted_indices:\n",
        "                token = idx_to_token.get(token_idx, '')\n",
        "                # Stop decoding when a padding token is encountered\n",
        "                if token == '`':\n",
        "                    break\n",
        "                generated_smiles += token\n",
        "\n",
        "            # Validate and display the generated SMILES string as an image\n",
        "            mol = Chem.MolFromSmiles(generated_smiles)\n",
        "            if mol is not None:\n",
        "                print(f\"Generated molecule (valid SMILES): {generated_smiles}\")\n",
        "                img = MolToImage(mol)\n",
        "                display(img)\n",
        "            else:\n",
        "                print(f\"Generated molecule (invalid SMILES): {generated_smiles}\")\n",
        "\n",
        "            generated_molecules.append(generated_smiles)\n",
        "\n",
        "    return generated_molecules\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Determine the device to use (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Define an example protein sequence to predict for\n",
        "    target_protein_sequence = 'MGNASNDSQSEDCETRQWLPPGESPAISSVMFSAGVLGNLIALALLARRWRGDVGCSAGRRSSLSLFHVLVTELVFTDLLGTCLISPVVLASYARNQTLVALAPESRACTYFAFAMTFFSLATMLMLFAMALERYLSIGHPYFYQRRVSRSGGLAVLPVIYAVSLLFCSLPLLDYGQYVQYCPGTWCFIRHGRTAYLQLYATLLLLLIVSVLACNFSVILNLIRMHRRSRRSRCGPSLGSGRGGPGARRRGERVSMAEETDHLILLAIMTITFAVCSLPFTIFAYMNETSSRKEKWDLQALRFLSINSIIDPWVFAILRPPVLRLMRSVLCCRISLRTQDATQTSCSTQSDASKQADL'\n",
        "\n",
        "    # --- Training Process ---\n",
        "    try:\n",
        "        df = pd.read_csv('final_output_15_2_25.csv')\n",
        "        smiles_list = df['SMILES'].tolist()\n",
        "        protein_list = df['TARGET_SEQUENCE'].tolist()\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: The data file 'final_output_15_2_25.csv' was not found. Please ensure it is uploaded.\")\n",
        "        exit()\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    full_dataset = SmilesProteinDataset(smiles_list, protein_list, SMILES_TOKEN_DICT, SMILES_MAX_LEN, sorted_tokens)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialize the model and optimizer\n",
        "    protein_embedding_dim = len(get_protein_embedding(target_protein_sequence))\n",
        "    model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        print(f\"--- Epoch {epoch+1}/{MAX_EPOCHS} ---\")\n",
        "        train_loss = train_model(model, train_dataloader, optimizer, device, len(SMILES_TOKEN_DICT))\n",
        "        val_loss = validate_model(model, val_dataloader, device, len(SMILES_TOKEN_DICT))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{MAX_EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Check for improvement and save the best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            print(f\"Validation loss improved. Saving model to {MODEL_SAVE_PATH}\")\n",
        "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Validation loss did not improve. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nTraining complete. Model saved to '{MODEL_SAVE_PATH}'.\")\n",
        "\n",
        "    # --- Generation Process ---\n",
        "    # We load the best model to ensure we are using the one with the best performance\n",
        "    best_model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "    # Generate new molecules using the loaded model\n",
        "    generate_new_molecules(best_model, SMILES_TOKEN_DICT, target_protein_sequence, num_molecules=5, device=device, latent_dim=LATENT_DIM)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qjr6Tmoww0wF",
        "outputId": "ceb8fc72-5393-4dd8-a441-9d9e60f4df22"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting training...\n",
            "--- Epoch 1/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:42<00:00, 16.33it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 3625.3739, Validation Loss: 303.5562\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 2/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.51it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100, Train Loss: 252.6192, Validation Loss: 223.7039\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 3/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.57it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100, Train Loss: 208.5750, Validation Loss: 202.9897\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 4/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.52it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100, Train Loss: 193.4071, Validation Loss: 188.1752\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 5/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.51it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100, Train Loss: 187.0818, Validation Loss: 187.5296\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 6/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.47it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100, Train Loss: 184.0484, Validation Loss: 181.3712\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 7/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.56it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100, Train Loss: 180.1206, Validation Loss: 178.6909\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 8/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.51it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:16<00:00, 18.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100, Train Loss: 177.3840, Validation Loss: 177.9370\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 9/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.52it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100, Train Loss: 176.5505, Validation Loss: 174.8364\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 10/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.59it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Train Loss: 174.9801, Validation Loss: 175.5028\n",
            "Validation loss did not improve. Patience: 1/15\n",
            "--- Epoch 11/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.53it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100, Train Loss: 173.9497, Validation Loss: 174.5714\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 12/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.54it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100, Train Loss: 173.0965, Validation Loss: 174.6432\n",
            "Validation loss did not improve. Patience: 1/15\n",
            "--- Epoch 13/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.51it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100, Train Loss: 172.6434, Validation Loss: 174.4912\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 14/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:42<00:00, 16.34it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100, Train Loss: 170.7696, Validation Loss: 172.2574\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 15/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.44it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100, Train Loss: 171.4175, Validation Loss: 181.2980\n",
            "Validation loss did not improve. Patience: 1/15\n",
            "--- Epoch 16/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.55it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100, Train Loss: 169.9664, Validation Loss: 169.9278\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 17/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.41it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100, Train Loss: 168.8427, Validation Loss: 172.6575\n",
            "Validation loss did not improve. Patience: 1/15\n",
            "--- Epoch 18/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.56it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100, Train Loss: 169.2395, Validation Loss: 171.5446\n",
            "Validation loss did not improve. Patience: 2/15\n",
            "--- Epoch 19/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.46it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100, Train Loss: 169.1551, Validation Loss: 170.4190\n",
            "Validation loss did not improve. Patience: 3/15\n",
            "--- Epoch 20/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.40it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Train Loss: 169.0820, Validation Loss: 174.9894\n",
            "Validation loss did not improve. Patience: 4/15\n",
            "--- Epoch 21/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.43it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:15<00:00, 18.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100, Train Loss: 168.8205, Validation Loss: 168.0433\n",
            "Validation loss improved. Saving model to best_model.pt\n",
            "--- Epoch 22/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 687/687 [00:41<00:00, 16.42it/s]\n",
            "Validation: 100%|██████████| 295/295 [00:16<00:00, 18.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100, Train Loss: 168.9682, Validation Loss: 171.0176\n",
            "Validation loss did not improve. Patience: 1/15\n",
            "--- Epoch 23/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  17%|█▋        | 119/687 [00:07<00:35, 16.18it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2650253706.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- Epoch {epoch+1}/{MAX_EPOCHS} ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSMILES_TOKEN_DICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSMILES_TOKEN_DICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2650253706.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, device, smiles_vocab_size)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cgGdjLecJ31t",
        "outputId": "69a7dcae-3d87-4914-d4a8-95713f7e37e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppress RDKit warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Global constants for a comprehensive SMILES vocabulary ---\n",
        "def create_comprehensive_smiles_vocab():\n",
        "    \"\"\"\n",
        "    Creates a comprehensive SMILES token vocabulary based on the periodic table,\n",
        "    numbers, and common SMILES characters.\n",
        "    \"\"\"\n",
        "    periodic_table_elements = [\n",
        "        'H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si',\n",
        "        'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
        "        'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb',\n",
        "        'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
        "        'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho',\n",
        "        'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
        "        'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np',\n",
        "        'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg',\n",
        "        'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og'\n",
        "    ]\n",
        "    # Common SMILES single characters\n",
        "    single_char_tokens = [\n",
        "        '(', ')', '[', ']', '+', '-', '=', '#', '.', ':', '/', '\\\\',\n",
        "        'c', 'n', 'o', 's', '`', '@'\n",
        "    ]\n",
        "    # Numbers\n",
        "    numbers = [str(i) for i in range(10)]\n",
        "\n",
        "    # Combine all tokens and remove duplicates\n",
        "    all_tokens = set(periodic_table_elements + single_char_tokens + numbers)\n",
        "    # Add start and padding tokens\n",
        "    all_tokens.add('#') # Start token\n",
        "    all_tokens.add('`') # Padding token\n",
        "\n",
        "    # Sort tokens by length in descending order to handle multi-character tokens correctly\n",
        "    sorted_tokens = sorted(list(all_tokens), key=len, reverse=True)\n",
        "    # Create the dictionary\n",
        "    smiles_token_dict = {token: i for i, token in enumerate(sorted_tokens)}\n",
        "\n",
        "    return smiles_token_dict, sorted_tokens\n",
        "\n",
        "SMILES_TOKEN_DICT, sorted_tokens = create_comprehensive_smiles_vocab()\n",
        "SMILES_MAX_LEN = 1000\n",
        "HIDDEN_DIM = 64\n",
        "LATENT_DIM = 128\n",
        "NUM_LAYERS = 2\n",
        "MAX_EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 15\n",
        "LEARNING_RATE = 1e-3\n",
        "MODEL_SAVE_PATH = 'best_model.pt'\n",
        "\n",
        "# --- Data Preprocessing and PyTorch Dataset ---\n",
        "def get_smiles_tokens(smiles_string, special_tokens):\n",
        "    \"\"\"\n",
        "    Tokenizes a SMILES string using a predefined list of special tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles_string):\n",
        "        matched = False\n",
        "        for token in special_tokens:\n",
        "            if smiles_string.startswith(token, i):\n",
        "                tokens.append(token)\n",
        "                i += len(token)\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            tokens.append(smiles_string[i])\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "def smiles_to_one_hot(smiles, token_to_idx, max_len, sorted_tokens):\n",
        "    \"\"\"Encodes a SMILES string into a one-hot vector with padding.\"\"\"\n",
        "    tokens = get_smiles_tokens(smiles, sorted_tokens)\n",
        "\n",
        "    if len(tokens) > max_len:\n",
        "        tokens = tokens[:max_len]\n",
        "\n",
        "    # Pad with padding token\n",
        "    padded_tokens = tokens + ['`'] * (max_len - len(tokens))\n",
        "\n",
        "    one_hot_vector = np.zeros((max_len, len(token_to_idx)), dtype=np.float32)\n",
        "    for i, token in enumerate(padded_tokens):\n",
        "        if token in token_to_idx:\n",
        "            one_hot_vector[i, token_to_idx[token]] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "def get_protein_embedding(seq):\n",
        "    \"\"\"\n",
        "    A simple, placeholder protein embedding function.\n",
        "    In a real-world scenario, you would use a more sophisticated method,\n",
        "    like a pre-trained protein language model (e.g., from the ProtTrans or ESM family)\n",
        "    for better performance on complex protein sequences.\n",
        "    \"\"\"\n",
        "    protein_vocab = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10,\n",
        "                     'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
        "    embedding = np.zeros(len(protein_vocab), dtype=np.float32)\n",
        "    for amino_acid in seq:\n",
        "        if amino_acid in protein_vocab:\n",
        "            embedding[protein_vocab[amino_acid]] = 1\n",
        "    return embedding\n",
        "\n",
        "class SmilesProteinDataset(Dataset):\n",
        "    \"\"\"Dataset for loading SMILES and Protein sequence pairs.\"\"\"\n",
        "    def __init__(self, smiles_list, protein_list, smiles_token_dict, smiles_max_len, sorted_tokens):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.protein_list = protein_list\n",
        "        self.smiles_token_dict = smiles_token_dict\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.sorted_tokens = sorted_tokens\n",
        "        # The protein embedding dimension is determined from the first sequence in the list\n",
        "        self.protein_embedding_dim = len(get_protein_embedding(self.protein_list[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles_list[idx]\n",
        "        protein = self.protein_list[idx]\n",
        "        smiles_one_hot = smiles_to_one_hot(smiles, self.smiles_token_dict, self.smiles_max_len, self.sorted_tokens)\n",
        "        protein_embedding = get_protein_embedding(protein)\n",
        "        return torch.tensor(smiles_one_hot, dtype=torch.float32), torch.tensor(protein_embedding, dtype=torch.float32)\n",
        "\n",
        "# --- Conditional VAE Model Definition ---\n",
        "\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, smiles_vocab_size, protein_embedding_dim, hidden_dim, latent_dim, smiles_max_len, num_layers):\n",
        "        super(ConditionalVAE, self).__init__()\n",
        "\n",
        "        self.smiles_max_len = smiles_max_len\n",
        "        self.smiles_vocab_size = smiles_vocab_size\n",
        "        self.protein_embedding_dim = protein_embedding_dim\n",
        "\n",
        "        # Encoder: takes smiles and protein embedding as input\n",
        "        self.encoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.encoder_protein_mlp = nn.Sequential(\n",
        "            nn.Linear(protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder: takes latent vector and protein embedding as input\n",
        "        self.decoder_gru_input_mlp = nn.Sequential(\n",
        "            nn.Linear(latent_dim + protein_embedding_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder_rnn = nn.GRU(\n",
        "            input_size=smiles_vocab_size,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc_output = nn.Linear(hidden_dim, smiles_vocab_size)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick to sample from N(mu, var)\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encoder(self, smiles_one_hot, protein_embedding):\n",
        "        _, hidden_smiles = self.encoder_rnn(smiles_one_hot)\n",
        "        hidden_protein = self.encoder_protein_mlp(protein_embedding).unsqueeze(0).repeat(hidden_smiles.size(0), 1, 1)\n",
        "        combined_hidden = hidden_smiles + hidden_protein\n",
        "        final_hidden_state = combined_hidden[-1, :, :]\n",
        "        mu = self.fc_mu(final_hidden_state)\n",
        "        logvar = self.fc_logvar(final_hidden_state)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decoder(self, z, protein_embedding):\n",
        "        z_with_protein = torch.cat((z, protein_embedding), dim=1)\n",
        "        initial_hidden = self.decoder_gru_input_mlp(z_with_protein).unsqueeze(0)\n",
        "        initial_hidden = initial_hidden.repeat(self.decoder_rnn.num_layers, 1, 1)\n",
        "        decoder_input = torch.zeros(z.size(0), self.smiles_max_len, self.smiles_vocab_size).to(z.device)\n",
        "        output, _ = self.decoder_rnn(decoder_input, initial_hidden)\n",
        "        output = self.fc_output(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, smiles_one_hot, protein_embedding):\n",
        "        mu, logvar = self.encoder(smiles_one_hot, protein_embedding)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_smiles = self.decoder(z, protein_embedding)\n",
        "        return reconstructed_smiles, mu, logvar\n",
        "\n",
        "# --- Training Loop and Generation ---\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar, smiles_vocab_size):\n",
        "    \"\"\"VAE loss function: BCE + KL divergence.\"\"\"\n",
        "    # Ensure dimensions are compatible for BCE calculation\n",
        "    recon_x_flat = recon_x.view(-1, smiles_vocab_size)\n",
        "    x_flat = x.view(-1, smiles_vocab_size)\n",
        "    BCE = nn.functional.binary_cross_entropy_with_logits(recon_x_flat, x_flat, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def train_model(model, dataloader, optimizer, device, smiles_vocab_size):\n",
        "    \"\"\"Trains the VAE model for one epoch with a progress bar.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for smiles_oh, protein_emb in tqdm(dataloader, desc=\"Training\"):\n",
        "        smiles_oh = smiles_oh.to(device)\n",
        "        protein_emb = protein_emb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "        loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def validate_model(model, dataloader, device, smiles_vocab_size):\n",
        "    \"\"\"Evaluates the model on the validation set.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for smiles_oh, protein_emb in tqdm(dataloader, desc=\"Validation\"):\n",
        "            smiles_oh = smiles_oh.to(device)\n",
        "            protein_emb = protein_emb.to(device)\n",
        "\n",
        "            reconstructed_smiles, mu, logvar = model(smiles_oh, protein_emb)\n",
        "            loss = vae_loss(reconstructed_smiles, smiles_oh, mu, logvar, smiles_vocab_size)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def generate_new_molecules(model, smiles_token_dict, protein_seq, num_molecules, device, latent_dim):\n",
        "    \"\"\"Generates and visualizes new molecules for a given protein sequence.\"\"\"\n",
        "    model.eval()\n",
        "    idx_to_token = {v: k for k, v in smiles_token_dict.items()}\n",
        "    generated_molecules = []\n",
        "\n",
        "    # Prepare the protein embedding for a single sequence\n",
        "    protein_embedding = get_protein_embedding(protein_seq)\n",
        "    protein_embedding = torch.tensor(protein_embedding, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    print(f\"\\nAttempting to generate {num_molecules} molecules for protein sequence: {protein_seq}\")\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_molecules):\n",
        "            # Sample a vector from the latent space\n",
        "            z = torch.randn(1, latent_dim).to(device)\n",
        "            # Use the decoder to generate a one-hot encoded SMILES string\n",
        "            generated_output = model.decoder(z, protein_embedding)\n",
        "\n",
        "            # Use softmax to get probabilities for each token and then select the most likely one\n",
        "            probabilities = nn.functional.softmax(generated_output, dim=-1)\n",
        "            predicted_indices = torch.argmax(probabilities, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "            generated_smiles = \"\"\n",
        "            for token_idx in predicted_indices:\n",
        "                token = idx_to_token.get(token_idx, '')\n",
        "                # Stop decoding when a padding token is encountered\n",
        "                if token == '`':\n",
        "                    break\n",
        "                generated_smiles += token\n",
        "\n",
        "            # Validate and display the generated SMILES string as an image\n",
        "            mol = Chem.MolFromSmiles(generated_smiles)\n",
        "            if mol is not None:\n",
        "                print(f\"Generated molecule (valid SMILES): {generated_smiles}\")\n",
        "                img = MolToImage(mol)\n",
        "                display(img)\n",
        "            else:\n",
        "                print(f\"Generated molecule (invalid SMILES): {generated_smiles}\")\n",
        "\n",
        "            generated_molecules.append(generated_smiles)\n",
        "\n",
        "    return generated_molecules\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Determine the device to use (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Define the path to the newly created CSV file in Google Drive\n",
        "    csv_file_path = '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'\n",
        "\n",
        "    # Define an example protein sequence to predict for\n",
        "    target_protein_sequence = 'MGNASNDSQSEDCETRQWLPPGESPAISSVMFSAGVLGNLIALALLARRWRGDVGCSAGRRSSLSLFHVLVTELVFTDLLGTCLISPVVLASYARNQTLVALAPESRACTYFAFAMTFFSLATMLMLFAMALERYLSIGHPYFYQRRVSRSGGLAVLPVIYAVSLLFCSLPLLDYGQYVQYCPGTWCFIRHGRTAYLQLYATLLLLLIVSVLACNFSVILNLIRMHRRSRRSRCGPSLGSGRGGPGARRRGERVSMAEETDHLILLAIMTITFAVCSLPFTIFAYMNETSSRKEKWDLQALRFLSINSIIDPWVFAILRPPVLRLMRSVLCCRISLRTQDATQTSCSTQSDASKQADL'\n",
        "\n",
        "    # --- Data Loading ---\n",
        "    try:\n",
        "        # Load the CSV file from the specified Google Drive path\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "        # Ensure the column names match the new dataset\n",
        "        smiles_list = df['SMILES'].tolist()\n",
        "        protein_list = df['Protein_Sequence'].tolist()\n",
        "        print(f\"Successfully loaded {len(smiles_list)} data points from '{csv_file_path}'.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The data file '{csv_file_path}' was not found.\")\n",
        "        print(\"Please ensure the file has been created by the previous script and is in the correct directory.\")\n",
        "        exit()\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    full_dataset = SmilesProteinDataset(smiles_list, protein_list, SMILES_TOKEN_DICT, SMILES_MAX_LEN, sorted_tokens)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialize the model and optimizer\n",
        "    protein_embedding_dim = len(get_protein_embedding(target_protein_sequence))\n",
        "    model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        print(f\"--- Epoch {epoch+1}/{MAX_EPOCHS} ---\")\n",
        "        train_loss = train_model(model, train_dataloader, optimizer, device, len(SMILES_TOKEN_DICT))\n",
        "        val_loss = validate_model(model, val_dataloader, device, len(SMILES_TOKEN_DICT))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{MAX_EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Check for improvement and save the best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            print(f\"Validation loss improved. Saving model to {MODEL_SAVE_PATH}\")\n",
        "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Validation loss did not improve. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nTraining complete. Model saved to '{MODEL_SAVE_PATH}'.\")\n",
        "\n",
        "    # --- Generation Process ---\n",
        "    # We load the best model to ensure we are using the one with the best performance\n",
        "    best_model = ConditionalVAE(\n",
        "        smiles_vocab_size=len(SMILES_TOKEN_DICT),\n",
        "        protein_embedding_dim=protein_embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        latent_dim=LATENT_DIM,\n",
        "        smiles_max_len=SMILES_MAX_LEN,\n",
        "        num_layers=NUM_LAYERS\n",
        "    ).to(device)\n",
        "    best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "    # Generate new molecules using the loaded model\n",
        "    generate_new_molecules(best_model, SMILES_TOKEN_DICT, target_protein_sequence, num_molecules=5, device=device, latent_dim=LATENT_DIM)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yo6x9vV_rcx",
        "outputId": "416f2869-cbae-442d-f1fd-6153573371b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Successfully loaded 3046040 data points from '/content/drive/MyDrive/Drug_Database/bindingdb_dataset.csv'.\n",
            "Starting training...\n",
            "--- Epoch 1/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 491/66633 [00:31<1:09:12, 15.93it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}